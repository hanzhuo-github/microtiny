const e=JSON.parse('{"key":"v-45f1f552","path":"/ai/huggingface-nlp/section1/Chapter2.html","title":"2. 使用 🤗 Transformers","lang":"zh-CN","frontmatter":{"lang":"zh-CN","title":"2. 使用 🤗 Transformers","article":false},"headers":[{"level":2,"title":"1. Pipeline 都做了什么","slug":"_1-pipeline-都做了什么","link":"#_1-pipeline-都做了什么","children":[{"level":3,"title":"1.1 使用 tokenizer 进行预处理","slug":"_1-1-使用-tokenizer-进行预处理","link":"#_1-1-使用-tokenizer-进行预处理","children":[]},{"level":3,"title":"1.2 model","slug":"_1-2-model","link":"#_1-2-model","children":[{"level":4,"title":"1.2.1 Model 输出（hidden states 或 features）：高维张量","slug":"_1-2-1-model-输出-hidden-states-或-features-高维张量","link":"#_1-2-1-model-输出-hidden-states-或-features-高维张量","children":[]},{"level":4,"title":"1.2.2 Model heads","slug":"_1-2-2-model-heads","link":"#_1-2-2-model-heads","children":[]}]},{"level":3,"title":"1.3 后处理","slug":"_1-3-后处理","link":"#_1-3-后处理","children":[]}]},{"level":2,"title":"2. Models","slug":"_2-models","link":"#_2-models","children":[{"level":3,"title":"2.1 创建 Transformer","slug":"_2-1-创建-transformer","link":"#_2-1-创建-transformer","children":[{"level":4,"title":"2.1.1 不同的加载方法","slug":"_2-1-1-不同的加载方法","link":"#_2-1-1-不同的加载方法","children":[]},{"level":4,"title":"2.1.2 保存方法","slug":"_2-1-2-保存方法","link":"#_2-1-2-保存方法","children":[]}]},{"level":3,"title":"2.2 使用 Transformer 进行推理（inference）","slug":"_2-2-使用-transformer-进行推理-inference","link":"#_2-2-使用-transformer-进行推理-inference","children":[]}]},{"level":2,"title":"3. Tokenizers","slug":"_3-tokenizers","link":"#_3-tokenizers","children":[{"level":3,"title":"3.1 tokenization 算法","slug":"_3-1-tokenization-算法","link":"#_3-1-tokenization-算法","children":[{"level":4,"title":"3.1.1 Word-based","slug":"_3-1-1-word-based","link":"#_3-1-1-word-based","children":[]},{"level":4,"title":"3.1.2 Character-based","slug":"_3-1-2-character-based","link":"#_3-1-2-character-based","children":[]},{"level":4,"title":"3.1.3 Subword tokenization","slug":"_3-1-3-subword-tokenization","link":"#_3-1-3-subword-tokenization","children":[]}]},{"level":3,"title":"3.2 加载 & 保存","slug":"_3-2-加载-保存","link":"#_3-2-加载-保存","children":[]},{"level":3,"title":"3.3 编码（Encoding）","slug":"_3-3-编码-encoding","link":"#_3-3-编码-encoding","children":[{"level":4,"title":"3.3.1 Tokenization","slug":"_3-3-1-tokenization","link":"#_3-3-1-tokenization","children":[]},{"level":4,"title":"3.3.2 将 tokens 转换为 input IDs","slug":"_3-3-2-将-tokens-转换为-input-ids","link":"#_3-3-2-将-tokens-转换为-input-ids","children":[]}]},{"level":3,"title":"3.4 解码（Decoding）","slug":"_3-4-解码-decoding","link":"#_3-4-解码-decoding","children":[]},{"level":3,"title":"3.5 小结","slug":"_3-5-小结","link":"#_3-5-小结","children":[]}]},{"level":2,"title":"4. 处理多个序列","slug":"_4-处理多个序列","link":"#_4-处理多个序列","children":[{"level":3,"title":"4.1 批处理","slug":"_4-1-批处理","link":"#_4-1-批处理","children":[]}]},{"level":2,"title":"4.2 填充（Padding）","slug":"_4-2-填充-padding","link":"#_4-2-填充-padding","children":[{"level":3,"title":"4.3 Attention Masks","slug":"_4-3-attention-masks","link":"#_4-3-attention-masks","children":[]},{"level":3,"title":"4.4 长序列","slug":"_4-4-长序列","link":"#_4-4-长序列","children":[]}]},{"level":2,"title":"5. Tokenizer API","slug":"_5-tokenizer-api","link":"#_5-tokenizer-api","children":[{"level":3,"title":"5.1 特殊 token","slug":"_5-1-特殊-token","link":"#_5-1-特殊-token","children":[]},{"level":3,"title":"5.2 小结","slug":"_5-2-小结","link":"#_5-2-小结","children":[]}]},{"level":2,"title":"总结","slug":"总结","link":"#总结","children":[]}],"git":{"createdTime":1700236816000,"updatedTime":1700236816000,"contributors":[{"name":"Sunshine","email":"hanzhuosoul@gmail.com","commits":1}]},"readingTime":{"minutes":23.16,"words":6947},"filePathRelative":"ai/huggingface-nlp/section1/Chapter2.md","localizedDate":"2023年11月17日","excerpt":"<p>Transformer 模型一般都很大，训练或者部署是一项复杂的任务。🤗 Transformers 库提供了简单的API，使得用户可以通过它来加载、训练、保存所有的 Transformer 模型。</p>\\n<p>我们将使用 model 和 tokenizer 来实现在上一节中 <code>pipeline()</code> 函数完成的任务。然后会介绍 model API，看一看 model 类和 configuration 类，了解如何加载模型、它是怎么处理数字输入并输出预测的。</p>\\n<p>接下来还有 tokenizer API。tokenizer 负责将文本转成数字表示（以作为神经网络的输入），并负责将数字表示转化成文本。我们还会展示如何批处理多个句子。</p>"}');export{e as data};
