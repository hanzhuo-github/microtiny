import{_ as d}from"./plugin-vue_export-helper-c27b6911.js";import{r as c,o as r,c as u,d as n,e as a,f as o,w as s,b as l}from"./app-e50f947d.js";const m={},g={href:"https://huggingface.co/",target:"_blank",rel:"noopener noreferrer"},k=n("p",null,"å…¶ä¸­çš„æ¨¡å‹ä¸å±€é™äº ğŸ¤— Transformers æˆ–è€… NLPã€‚ä½ å¯ä»¥è‡ªå·±å»æ¢ç´¢ã€‚",-1),h=n("p",null,"æ¨¡å‹éƒ½ç”¨ Git è¿›è¡Œæ‰˜ç®¡ï¼Œå…è®¸ç‰ˆæœ¬æ§åˆ¶å’Œé‡ç°ã€‚å¦å¤–ï¼Œåœ¨ Hub ä¸Šå…±äº«æ¨¡å‹ä¼šè‡ªåŠ¨ä¸ºè¯¥æ¨¡å‹éƒ¨ç½²æ‰˜ç®¡çš„æ¨ç† APIã€‚",-1),b=n("h2",{id:"_1-ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#_1-ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹","aria-hidden":"true"},"#"),a(" 1. ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹")],-1),v=n("p",null,"å¦‚æˆ‘ä»¬è¦ä½¿ç”¨ camembert-base checkpoints.",-1),_=n("div",{class:"language-python line-numbers-mode","data-ext":"py"},[n("pre",{class:"language-python"},[n("code",null,[n("span",{class:"token comment"},"# ä½¿ç”¨ pipeline"),a(`
`),n("span",{class:"token keyword"},"from"),a(" transformers "),n("span",{class:"token keyword"},"import"),a(` pipeline

camembert_fill_mask `),n("span",{class:"token operator"},"="),a(" pipeline"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"fill-mask"'),n("span",{class:"token punctuation"},","),a(" model"),n("span",{class:"token operator"},"="),n("span",{class:"token string"},'"camembert-base"'),n("span",{class:"token punctuation"},")"),a(`
results `),n("span",{class:"token operator"},"="),a(" camembert_fill_mask"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"Le camembert est <mask> :)"'),n("span",{class:"token punctuation"},")"),a(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),f=n("div",{class:"language-python line-numbers-mode","data-ext":"py"},[n("pre",{class:"language-python"},[n("code",null,[n("span",{class:"token comment"},"# ç›´æ¥ä½¿ç”¨ model architecture"),a(`
`),n("span",{class:"token keyword"},"from"),a(" transformers "),n("span",{class:"token keyword"},"import"),a(" CamembertTokenizer"),n("span",{class:"token punctuation"},","),a(` CamembertForMaskedLM

tokenizer `),n("span",{class:"token operator"},"="),a(" CamembertTokenizer"),n("span",{class:"token punctuation"},"."),a("from_pretrained"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"camembert-base"'),n("span",{class:"token punctuation"},")"),a(`
model `),n("span",{class:"token operator"},"="),a(" CamembertForMaskedLM"),n("span",{class:"token punctuation"},"."),a("from_pretrained"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"camembert-base"'),n("span",{class:"token punctuation"},")"),a(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),y=n("div",{class:"language-python line-numbers-mode","data-ext":"py"},[n("pre",{class:"language-python"},[n("code",null,[n("span",{class:"token comment"},"# æ¨èä½¿ç”¨ Auto* Classï¼Œå› ä¸ºè¿™ç§å®ç°ä¸ architecture æ— å…³"),a(`
`),n("span",{class:"token keyword"},"from"),a(" transformers "),n("span",{class:"token keyword"},"import"),a(" AutoTokenizer"),n("span",{class:"token punctuation"},","),a(` AutoModelForMaskedLM

tokenizer `),n("span",{class:"token operator"},"="),a(" AutoTokenizer"),n("span",{class:"token punctuation"},"."),a("from_pretrained"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"camembert-base"'),n("span",{class:"token punctuation"},")"),a(`
model `),n("span",{class:"token operator"},"="),a(" AutoModelForMaskedLM"),n("span",{class:"token punctuation"},"."),a("from_pretrained"),n("span",{class:"token punctuation"},"("),n("span",{class:"token string"},'"camembert-base"'),n("span",{class:"token punctuation"},")"),a(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),x=l('<div class="hint-container tip"><p class="hint-container-title">æç¤º</p><p>ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æ—¶ï¼Œå¯ä»¥åœ¨ model card ä¸­æŸ¥çœ‹å®ƒæ˜¯å¦‚ä½•è®­ç»ƒçš„ï¼Œåœ¨å“ªäº›æ•°æ®é›†ä¸Šè®­ç»ƒçš„ï¼Œå±€é™æ€§å’Œ bias ã€‚</p></div><h2 id="_2-å…±äº«é¢„è®­ç»ƒæ¨¡å‹" tabindex="-1"><a class="header-anchor" href="#_2-å…±äº«é¢„è®­ç»ƒæ¨¡å‹" aria-hidden="true">#</a> 2. å…±äº«é¢„è®­ç»ƒæ¨¡å‹</h2><p>åˆ›å»ºæ¨¡å‹ä»“åº“çš„ä¸‰ç§æ–¹æ³•ï¼š</p><ul><li>ä½¿ç”¨ <code>push_to_hub</code> API</li><li>ä½¿ç”¨ <code>huggingface_hub</code> python åº“</li><li>åœ¨ web é¡µé¢ä¸Šåˆ›å»º</li></ul><p>åˆ›å»ºå¥½ä»“åº“åï¼Œå°±å¯ä»¥é€šè¿‡ git æˆ–è€… git-lfs ä¸Šä¼ æ–‡ä»¶äº†ã€‚</p><h3 id="_2-1-åˆ›å»ºæ¨¡å‹ä»“åº“" tabindex="-1"><a class="header-anchor" href="#_2-1-åˆ›å»ºæ¨¡å‹ä»“åº“" aria-hidden="true">#</a> 2.1 åˆ›å»ºæ¨¡å‹ä»“åº“</h3><h4 id="_2-1-1-ä½¿ç”¨-push-to-hub-api" tabindex="-1"><a class="header-anchor" href="#_2-1-1-ä½¿ç”¨-push-to-hub-api" aria-hidden="true">#</a> 2.1.1 ä½¿ç”¨ <code>push_to_hub</code> API</h4><p>ä½ éœ€è¦èº«ä»½ä»¤ç‰Œä¸€é huggingface_hub çŸ¥é“ä½ çš„æƒé™ã€‚</p>',8),q=n("div",{class:"language-python line-numbers-mode","data-ext":"py"},[n("pre",{class:"language-python"},[n("code",null,[n("span",{class:"token keyword"},"from"),a(" huggingface_hub "),n("span",{class:"token keyword"},"import"),a(` notebook_login

notebook_login`),n("span",{class:"token punctuation"},"("),n("span",{class:"token punctuation"},")"),a(`
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),w=n("div",{class:"language-python line-numbers-mode","data-ext":"py"},[n("pre",{class:"language-python"},[n("code",null,[a("huggingface"),n("span",{class:"token operator"},"-"),a(`cli login
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"})])],-1),z=l(`<p>å¦‚æœä½ ä½¿ç”¨ Trainer API è®­ç»ƒæ¨¡å‹ï¼Œå°†æ¨¡å‹ä¸Šä¼ è‡³ Hub æœ€ç®€å•çš„æ–¹å¼å°±æ˜¯åœ¨å®šä¹‰ TrainerArguments æ—¶é…ç½® <code>push_to_hub=True</code></p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> transformers <span class="token keyword">import</span> TrainerArguments

training_args <span class="token operator">=</span> TrainerArguments<span class="token punctuation">(</span>
    <span class="token string">&quot;bert-finetuned-mrpc&quot;</span><span class="token punctuation">,</span> save_strategy<span class="token operator">=</span><span class="token string">&quot;epoch&quot;</span><span class="token punctuation">,</span> push_to_hub<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>å½“ä½ è°ƒç”¨ <code>trainer.train()</code> æ—¶ï¼ŒTrainer ä¼šåœ¨æ¯æ¬¡ä¿å­˜ model æ—¶ï¼ˆæŒ‰ç…§ä¸Šé¢çš„é…ç½®ï¼Œæ˜¯æ¯ä¸ª epochï¼‰å°†ä½ çš„ model ä¸Šä¼ åˆ° Hub ä¸­å¯¹åº”çš„ä»“åº“ä¸Šã€‚ä»“åº“åç§°ä¸ºä½ é€‰æ‹©çš„è¾“å‡ºè·¯å¾„ï¼ˆå¦‚ä¸Šé¢çš„ bert-finetuned-mrpcï¼‰ï¼Œä½ ä¹Ÿå¯ä»¥ç”¨ <code>hub_model_id=&quot;a_different_name&quot;</code> æ¥è®¾ç½®ä¸åŒçš„åç§°ã€‚å¦‚æœè¦å°† model ä¸Šä¼ åˆ°ä½ æ‰€åœ¨çš„ç»„ç»‡ä¸‹ï¼Œä½ å¯ä»¥ä½¿ç”¨ <code>hub_model_id=&quot;my_organization/mu_repo_name&quot;</code>ã€‚</p><p>è®­ç»ƒç»“æŸåï¼Œä½¿ç”¨ <code>trainer.push_to_hub()</code> ä¸Šä¼ æœ€åä¸€ç‰ˆ modelã€‚å®ƒä¼šç”Ÿæˆ model cardã€‚</p><p>åœ¨è¾ƒä½å±‚çš„å®ç°ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥é€šè¿‡ modelsã€tokenizersã€configuration å¯¹è±¡çš„ <code>push_to_hub()</code> æ–¹æ³•æ¥è®¿é—® Model Hubã€‚è¿™ç§æ–¹å¼æ—¢å¯ä»¥åˆ›å»ºä»“åº“ï¼Œåˆèƒ½å°† model å’Œ tokenizer æ–‡ä»¶ç›´æ¥æ¨åˆ°ä»“åº“ä¸­ã€‚</p><p>é¦–å…ˆåˆ›å»º model å’Œ tokenizerã€‚</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForMaskedLM<span class="token punctuation">,</span> AutoTokenizer

checkpoint <span class="token operator">=</span> <span class="token string">&quot;camembert-base&quot;</span>

model <span class="token operator">=</span> AutoModelForMaskedLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>ä½ å¯ä»¥è®­ç»ƒæ¨¡å‹ã€å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒã€å‘ tokenizer ä¸­å¢åŠ  tokensã€‚åšå®Œä½ æƒ³åšçš„äº‹æƒ…æ—¶å€™ï¼Œä½ å¯ä»¥ä½¿ç”¨ <code>push_to_hub()</code> å°† model æ¨åˆ°ä»“åº“ä¸­</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>model<span class="token punctuation">.</span>push_to_hub<span class="token punctuation">(</span><span class="token string">&quot;dummy-model&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>è¿™å°†ä¼šåˆ›å»ºåä¸º dummy-model çš„ä»“åº“ï¼Œå…¶ä¸­ä¼šå¡«ä¸Šä½ çš„ model æ–‡ä»¶ã€‚</p><p>åŒæ ·ï¼Œå¯¹ tokenizer ä¹Ÿå¯åšåŒæ ·çš„æ“ä½œã€‚ç°åœ¨ä½ çš„ä»“åº“ä¸­æœ‰äº†å…¨éƒ¨æ‰€éœ€çš„æ–‡ä»¶ã€‚</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>tokenizer<span class="token punctuation">.</span>push_to_hub<span class="token punctuation">(</span><span class="token string">&quot;dummy-model&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>å¦‚æœä½ æƒ³å°†ä»“åº“æ”¾åˆ°ç»„ç»‡ä¸‹ï¼š</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>tokenizer<span class="token punctuation">.</span>push_to_hub<span class="token punctuation">(</span><span class="token string">&quot;dummy-model&quot;</span><span class="token punctuation">,</span> organization<span class="token operator">=</span><span class="token string">&quot;huggingface&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>å¦‚æœä½ æƒ³ä½¿ç”¨æŸä¸ªç‰¹å®šçš„ Hugging Face tokenï¼š</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>tokenizer<span class="token punctuation">.</span>push_to_hub<span class="token punctuation">(</span><span class="token string">&quot;dummy-model&quot;</span><span class="token punctuation">,</span> organization<span class="token operator">=</span><span class="token string">&quot;huggingface&quot;</span><span class="token punctuation">,</span> use_auth_token<span class="token operator">=</span><span class="token string">&quot;&lt;TOKEN&gt;&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h4 id="_2-1-2-ä½¿ç”¨-huggingface-hub-python-åº“" tabindex="-1"><a class="header-anchor" href="#_2-1-2-ä½¿ç”¨-huggingface-hub-python-åº“" aria-hidden="true">#</a> 2.1.2 ä½¿ç”¨ <code>huggingface_hub</code> python åº“</h4><p>ä½ éœ€è¦ä½¿ç”¨ CLI çš„ç™»å½•å‘½ä»¤</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>huggingface-cli login
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>huggingface_hub åº“æä¾›äº†å¾ˆå¤šæ–¹æ³•å’Œç±»ã€‚ä¸‹é¢æ˜¯å’Œä»“åº“åˆ›å»ºã€åˆ é™¤ç­‰æœ‰å…³çš„æ–¹æ³•</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> huggingface_hub <span class="token keyword">import</span> <span class="token punctuation">(</span>
    <span class="token comment"># User management</span>
    login<span class="token punctuation">,</span>
    logout<span class="token punctuation">,</span>
    whoami<span class="token punctuation">,</span>

    <span class="token comment"># Repository creation and management</span>
    create_repo<span class="token punctuation">,</span>
    delete_repo<span class="token punctuation">,</span>
    update_repo_visibility<span class="token punctuation">,</span>

    <span class="token comment"># And some methods to retrieve/change information about the content</span>
    list_models<span class="token punctuation">,</span>
    list_datasets<span class="token punctuation">,</span>
    list_metrics<span class="token punctuation">,</span>
    list_repo_files<span class="token punctuation">,</span>
    upload_file<span class="token punctuation">,</span>
    delete_file<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># åˆ›å»ºä»“åº“</span>
<span class="token keyword">from</span> huggingface_hub <span class="token keyword">import</span> create_repo

create_repo<span class="token punctuation">(</span><span class="token string">&quot;dummy-model&quot;</span><span class="token punctuation">)</span>
<span class="token comment"># å¯ä»¥æŒ‡å®š organization</span>
<span class="token comment"># create_repo(&quot;dummy-model&quot;, organization=&quot;huggingface&quot;)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>é™¤äº†å¯ä»¥æŒ‡å®š organizationï¼Œè¿˜æœ‰ä¸€äº›å‚æ•°ï¼š</p><ul><li>private: æ˜¯å¦å¯¹å…¶ä»–äººå¯è§</li><li>token: æ˜¯å¦æƒ³ç”¨ç»™å®šçš„ token è¦†ç›–ç¼“å­˜ä¸­çš„ token</li><li>repo_type: æ˜¯éƒ½è¦åˆ›å»º dataset æˆ– spaceï¼ˆè€Œéåˆ›å»º modelï¼‰ã€‚æ¥å—çš„å€¼å¯ä»¥æ˜¯ â€œdatasetâ€ æˆ– â€œspaceâ€</li></ul><h4 id="_2-1-3-ä½¿ç”¨-web-é¡µé¢" tabindex="-1"><a class="header-anchor" href="#_2-1-3-ä½¿ç”¨-web-é¡µé¢" aria-hidden="true">#</a> 2.1.3 ä½¿ç”¨ web é¡µé¢</h4><p>è¿™é‡Œä¸å±•å¼€ä»‹ç»ï¼ŒæŒ‰ç…§é¡µé¢æç¤ºè¿›è¡Œå³å¯ã€‚</p><h3 id="_2-2-ä¸Šä¼ -model-files" tabindex="-1"><a class="header-anchor" href="#_2-2-ä¸Šä¼ -model-files" aria-hidden="true">#</a> 2.2 ä¸Šä¼  model files</h3><p>Hugging Face Hub çš„æ–‡ä»¶ç®¡ç†ç³»ç»ŸåŸºäº gitï¼ˆå¯¹äº regular filesï¼‰å’Œ git-lfsï¼ˆå¯¹äºå¤§æ–‡ä»¶ï¼Œlarge file storageï¼‰ã€‚</p><p>ä¸‹é¢æˆ‘ä»¬å°†ä»‹ç»ä¸‰ç§ä¸Šä¼ æ–‡ä»¶åˆ° Hub çš„æ–¹æ³•ã€‚</p><h4 id="_2-3-1-upload-file-æ–¹æ³•" tabindex="-1"><a class="header-anchor" href="#_2-3-1-upload-file-æ–¹æ³•" aria-hidden="true">#</a> 2.3.1 <code>upload_file</code> æ–¹æ³•</h4><p>ä½¿ç”¨ <code>upload_file()</code> ä¸éœ€è¦ git æˆ– git-lfsï¼Œå®ƒä½¿ç”¨ http post è¯·æ±‚å°†æ–‡ä»¶ç›´æ¥ä¼ åˆ° ğŸ¤— Hubã€‚ä½†æ˜¯å®ƒæ²¡æœ‰åŠæ³•å¤„ç† 5GB ä»¥ä¸Šçš„æ–‡ä»¶ã€‚</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> huggingface_hub <span class="token keyword">import</span> upload_file

upload_file<span class="token punctuation">(</span>
    <span class="token string">&quot;&lt;path_to_file&gt;/config.json&quot;</span><span class="token punctuation">,</span>
    path_in_repo<span class="token operator">=</span><span class="token string">&quot;config.json&quot;</span><span class="token punctuation">,</span>
    repo_id<span class="token operator">=</span><span class="token string">&quot;&lt;namespace&gt;/dummy-model&quot;</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>è¿˜æœ‰ä¸€äº›å…¶ä»–çš„å‚æ•°ï¼š</p><ul><li>token</li><li>repo_type</li></ul><h4 id="_2-3-2-repository-ç±»" tabindex="-1"><a class="header-anchor" href="#_2-3-2-repository-ç±»" aria-hidden="true">#</a> 2.3.2 <code>Repository</code> ç±»</h4><p><code>Repository</code> ç±»ä»¥äº git çš„æ–¹å¼ç®¡ç†æœ¬åœ°ä»“åº“ã€‚ä½¿ç”¨è¯¥ç±»éœ€è¦å®‰è£… git å’Œ git-lfs</p>`,36),A={class:"hint-container details"},M=n("summary",null,"å®‰è£… git-lfs",-1),T={href:"https://git-lfs.com/",target:"_blank",rel:"noopener noreferrer"},L=n("div",{class:"language-bash line-numbers-mode","data-ext":"sh"},[n("pre",{class:"language-bash"},[n("code",null,[n("span",{class:"token function"},"curl"),a(),n("span",{class:"token parameter variable"},"-s"),a(" https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh "),n("span",{class:"token operator"},"|"),a(),n("span",{class:"token function"},"sudo"),a(),n("span",{class:"token function"},"bash"),a(`
`),n("span",{class:"token function"},"sudo"),a(),n("span",{class:"token function"},"apt-get"),a(),n("span",{class:"token function"},"install"),a(` git-lfs
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"}),n("div",{class:"line-number"})])],-1),j=n("div",{class:"language-bash line-numbers-mode","data-ext":"sh"},[n("pre",{class:"language-bash"},[n("code",null,[a("brew "),n("span",{class:"token function"},"install"),a(` git-lfs
`)])]),n("div",{class:"line-numbers","aria-hidden":"true"},[n("div",{class:"line-number"})])],-1),F=l(`<p>:::</p><p>æˆ‘ä»¬ä½¿ç”¨åˆšåˆšå»ºå¥½çš„ä»“åº“ã€‚é¦–å…ˆæˆ‘ä»¬å…‹éš†è¿œç«¯ä»“åº“ï¼š</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> huggingface_hub <span class="token keyword">import</span> Repository

repo <span class="token operator">=</span> Repository<span class="token punctuation">(</span><span class="token string">&quot;&lt;path_to_dummy_folder&gt;&quot;</span><span class="token punctuation">,</span> clone_from<span class="token operator">=</span><span class="token string">&quot;&lt;namespace&gt;/dummy-model&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>è¿™å°†åœ¨æœ¬åœ°åˆ›å»ºæ–‡ä»¶å¤¹&lt;path_to_dummy_folder&gt;ã€‚è¯¥æ–‡ä»¶å¤¹ä¸­åŒ…å« .gitattributes æ–‡ä»¶ã€‚</p>`,4),C={href:"https://github.com/huggingface/huggingface_hub/tree/main/src/huggingface_hub#advanced-programmatic-repository-management",target:"_blank",rel:"noopener noreferrer"},H=l(`<div class="language-python" data-ext="py"><pre class="language-python"><code>repo<span class="token punctuation">.</span>git_pull<span class="token punctuation">(</span><span class="token punctuation">)</span>
repo<span class="token punctuation">.</span>git_add<span class="token punctuation">(</span><span class="token punctuation">)</span>
repo<span class="token punctuation">.</span>git_commit<span class="token punctuation">(</span><span class="token punctuation">)</span>
repo<span class="token punctuation">.</span>git_push<span class="token punctuation">(</span><span class="token punctuation">)</span>
repo<span class="token punctuation">.</span>git_tag<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><p>ç°åœ¨æˆ‘ä»¬æœ‰æƒ³è¦æ¨åˆ° Hub ä¸Šçš„ model å’Œ tokenizerï¼Œå¹¶æˆåŠŸ clone äº†ä»“åº“ã€‚</p><p>é¦–å…ˆï¼Œç¡®ä¿æˆ‘ä»¬æœ¬åœ° clone çš„ç‰ˆæœ¬æ˜¯æœ€æ–°çš„ï¼š</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>repo<span class="token punctuation">.</span>git_pull<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>ç„¶åæˆ‘ä»¬å°±å¯ä»¥ä¿å­˜ model å’Œ tokenizer files äº†ï¼š</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>model<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span><span class="token string">&quot;&lt;path_to_dummy_folder&gt;&quot;</span><span class="token punctuation">)</span>
tokenizer<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span><span class="token string">&quot;&lt;path_to_dummy_folder&gt;&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>ç›®å‰ï¼Œ&lt;path_to_dummy_folder&gt; ä¸­åŒ…å«äº†å…¨éƒ¨çš„ model å’Œ tokenizer filesã€‚æ¥ä¸‹æ¥å¯ä»¥ä½¿ç”¨ä¼ ç»Ÿçš„ git å·¥ä½œæµå°†ä»–ä»¬æ¨åˆ°è¿œç«¯ hubï¼š</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>repo<span class="token punctuation">.</span>git_add<span class="token punctuation">(</span><span class="token punctuation">)</span>
repo<span class="token punctuation">.</span>git_commit<span class="token punctuation">(</span><span class="token string">&quot;Add model and tokenizer files&quot;</span><span class="token punctuation">)</span>
repo<span class="token punctuation">.</span>git_push<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_2-3-3-git-based-æ–¹æ³•" tabindex="-1"><a class="header-anchor" href="#_2-3-3-git-based-æ–¹æ³•" aria-hidden="true">#</a> 2.3.3 <code>git-based</code> æ–¹æ³•</h4><p>ç›´æ¥ä½¿ç”¨ git å’Œ git-lfs æ¥ä¸Šä¼ æ–‡ä»¶ã€‚è¯·ç¡®ä¿å®‰è£…äº† git å’Œ git-lfsã€‚</p><p>é¦–å…ˆï¼Œåˆå§‹åŒ– git-lfs</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token function">git</span> lfs <span class="token function">install</span>
</code></pre></div><p>æ¥ä¸‹æ¥ï¼Œç¬¬ä¸€æ­¥æ˜¯å…‹éš† model ä»“åº“ï¼š</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token function">git</span> clone https://huggingface.co/<span class="token operator">&lt;</span>namespace<span class="token operator">&gt;</span>/<span class="token operator">&lt;</span>your-model-id<span class="token operator">&gt;</span>
</code></pre></div><p>ä¾‹å¦‚ï¼Œæˆ‘çš„ username æ˜¯ hanzhuoï¼Œä½¿ç”¨çš„ model name æ˜¯ dummy-model</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token function">git</span> clone https://huggingface.co/hanzhuo/dummy-model
</code></pre></div><p>ç°åœ¨æˆ‘çš„å·¥ä½œè·¯å¾„ä¸­æœ‰ä¸€ä¸ª dummy-model æ–‡ä»¶å¤¹ï¼Œ</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token builtin class-name">cd</span> dummy-model <span class="token operator">&amp;&amp;</span> <span class="token function">ls</span>
</code></pre></div><p>å¯ä»¥ä½¿ç”¨ git æ¥æ·»åŠ å°æ–‡ä»¶ï¼Œå¯¹äºå¤§æ–‡ä»¶ï¼Œéœ€è¦ä½¿ç”¨ git-lfsã€‚</p><p>å›é¡¾ä¸€ä¸‹ä¹‹å‰è·å¾— model å’Œ tokenizer çš„æ–¹å¼ï¼š</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForMaskedLM<span class="token punctuation">,</span> AutoTokenizer

checkpoint <span class="token operator">=</span> <span class="token string">&quot;camembert-base&quot;</span>

model <span class="token operator">=</span> AutoModelForMaskedLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>

<span class="token comment"># Do whatever with the model, train it, fine-tune it...</span>

model<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span><span class="token string">&quot;&lt;path_to_dummy_folder&gt;&quot;</span><span class="token punctuation">)</span>
tokenizer<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span><span class="token string">&quot;&lt;path_to_dummy_folder&gt;&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>æˆ‘ä»¬çœ‹ä¸€ä¸‹ dummy-model ä¸‹çš„æ–‡ä»¶ç›®å½•ï¼š</p><div class="language-text" data-ext="text"><pre class="language-text"><code>config.json  pytorch_model.bin  README.md  sentencepiece.bpe.model  special_tokens_map.json tokenizer_config.json  tokenizer.json
</code></pre></div><p>å¦‚æœä½¿ç”¨ <code>ls -lh</code> å‘½ä»¤ï¼Œå¯ä»¥å‘ç° pytorch_model.bin çš„å¤§å°è¶…è¿‡äº† 400MBã€‚</p><p>æ¥ä¸‹æ¥ä½¿ç”¨å¸¸è§„çš„ git å‘½ä»¤ï¼š</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token function">git</span> <span class="token function">add</span> <span class="token builtin class-name">.</span>
<span class="token function">git</span> status
</code></pre></div><div class="language-text" data-ext="text"><pre class="language-text"><code>On branch main
Your branch is up to date with &#39;origin/main&#39;.

Changes to be committed:
  (use &quot;git restore --staged &lt;file&gt;...&quot; to unstage)
  modified:   .gitattributes
	new file:   config.json
	new file:   pytorch_model.bin
	new file:   sentencepiece.bpe.model
	new file:   special_tokens_map.json
	new file:   tokenizer.json
	new file:   tokenizer_config.json
</code></pre></div><p>å†çœ‹ä¸€ä¸‹ git-lfs ï¼š</p><div class="language-bash" data-ext="sh"><pre class="language-bash"><code><span class="token function">git</span> lfs status
</code></pre></div><div class="language-text" data-ext="text"><pre class="language-text"><code>On branch main
Objects to be pushed to origin/main:


Objects to be committed:

	config.json (Git: bc20ff2)
	pytorch_model.bin (LFS: 35686c2)
	sentencepiece.bpe.model (LFS: 988bc5a)
	special_tokens_map.json (Git: cb23931)
	tokenizer.json (Git: 851ff3e)
	tokenizer_config.json (Git: f0f7783)

Objects not staged for commit:

</code></pre></div><p>å¯ä»¥è§‚å¯Ÿåˆ° <em>pytorch_model.bin</em> å’Œ <em>sentencepiece.bpe.model</em> ä½¿ç”¨çš„ LFSï¼Œå…¶ä½™çš„éƒ½æ˜¯ Gitã€‚</p><p>æœ€åï¼Œcommit å¹¶ push</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token function">git</span> commit <span class="token parameter variable">-m</span> <span class="token string">&quot;First model version&quot;</span>
<span class="token function">git</span> push
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_3-å»ºç«‹-model-card" tabindex="-1"><a class="header-anchor" href="#_3-å»ºç«‹-model-card" aria-hidden="true">#</a> 3. å»ºç«‹ model card</h2>`,34),E=n("em",null,"README.md",-1),R={href:"https://arxiv.org/abs/1810.03993",target:"_blank",rel:"noopener noreferrer"},G=l('<p>model card é€šå¸¸å¼€ç¯‡ä¸ºç®€çŸ­çš„æ¦‚è¿°è¯´æ˜å…¶ç”¨é€”ï¼Œç„¶åæ˜¯ä»¥ä¸‹å‡ éƒ¨åˆ†ï¼š</p><ul><li>Model description æè¿°</li><li>Intended uses &amp; limitations é¢„æœŸç”¨é€”å’Œé™åˆ¶</li><li>How to use å¦‚ä½•ä½¿ç”¨</li><li>Limitations and bias å±€é™æ€§å’Œåè§</li><li>Training data è®­ç»ƒæ•°æ®</li><li>Training procedure è®­ç»ƒè¿‡ç¨‹</li><li>Variable &amp; metrics è¯„ä¼°æŒ‡æ ‡</li><li>Evaluation results è¯„ä¼°ç»“æœ</li></ul><h3 id="model-card-metadata" tabindex="-1"><a class="header-anchor" href="#model-card-metadata" aria-hidden="true">#</a> Model card metadata</h3><p>åœ¨ Hugging Face Hub ä¸­ï¼Œæœ‰çš„ model å±äºç‰¹å®šçš„ç±»å‹ï¼Œä½ å¯ä»¥é€šè¿‡ tasks, languages, libraries ç­‰ç­‰æ¥ç­›é€‰ã€‚</p>',4),I={href:"https://huggingface.co/camembert-base/blob/main/README.md",target:"_blank",rel:"noopener noreferrer"},N=l(`<div class="language-markdown" data-ext="md"><pre class="language-markdown"><code><span class="token front-matter-block"><span class="token punctuation">---</span>
<span class="token front-matter yaml language-yaml"><span class="token key atrule">language</span><span class="token punctuation">:</span> fr
<span class="token key atrule">license</span><span class="token punctuation">:</span> mit
<span class="token key atrule">datasets</span><span class="token punctuation">:</span>
<span class="token punctuation">-</span> oscar</span>
<span class="token punctuation">---</span></span>
</code></pre></div>`,1),O={href:"https://github.com/huggingface/hub-docs/blame/main/modelcard.md",target:"_blank",rel:"noopener noreferrer"};function B(P,S){const i=c("ExternalLinkIcon"),p=c("CodeTabs");return r(),u("div",null,[n("p",null,[n("a",g,[a("Hugging Face Hub"),o(i)]),a(" æ˜¯ä¸»ç½‘ç«™ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨é‡Œé¢æ‰¾åˆ°å„ç§æœ€æ–°çš„æ¨¡å‹å’Œæ•°æ®é›†ï¼Œä¹Ÿå¯ä»¥ä¸Šä¼ è‡ªå·±çš„æ¨¡å‹å’Œæ•°æ®é›†ã€‚")]),k,h,b,v,o(p,{id:"15",data:[{id:"pipeline"},{id:"model architecture"},{id:"Auto* Class"}],"tab-id":"python"},{title0:s(({value:e,isActive:t})=>[a("pipeline")]),title1:s(({value:e,isActive:t})=>[a("model architecture")]),title2:s(({value:e,isActive:t})=>[a("Auto* Class")]),tab0:s(({value:e,isActive:t})=>[_]),tab1:s(({value:e,isActive:t})=>[f]),tab2:s(({value:e,isActive:t})=>[y]),_:1}),x,o(p,{id:"66",data:[{id:"Notebook"},{id:"Terminal"}]},{title0:s(({value:e,isActive:t})=>[a("Notebook")]),title1:s(({value:e,isActive:t})=>[a("Terminal")]),tab0:s(({value:e,isActive:t})=>[q]),tab1:s(({value:e,isActive:t})=>[w]),_:1}),z,n("details",A,[M,n("p",null,[a("å‚è€ƒ "),n("a",T,[a("Git Large File Storage"),o(i)])]),o(p,{id:"189",data:[{id:"Ubuntu"},{id:"Mac"}],"tab-id":"shell"},{title0:s(({value:e,isActive:t})=>[a("Ubuntu")]),title1:s(({value:e,isActive:t})=>[a("Mac")]),tab0:s(({value:e,isActive:t})=>[L]),tab1:s(({value:e,isActive:t})=>[j]),_:1})]),F,n("p",null,[a("æˆ‘ä»¬è¿˜ä¼šä½¿ç”¨ä¸€äº›ä¼ ç»Ÿçš„ git æ–¹æ³•ï¼Œå‚è€ƒ"),n("a",C,[a("æ–‡æ¡£"),o(i)]),a("ï¼š")]),H,n("p",null,[a("å»ºç«‹ model card æ˜¯é€šè¿‡ "),E,a(" æ¥å®Œæˆçš„ã€‚ä¸ºäº†ç†è§£ model card çš„é‡è¦ä½œç”¨ï¼Œä½ å¯ä»¥é˜…è¯» "),n("a",R,[a("Model Cards for Model Reporting"),o(i)]),a("ã€‚")]),G,n("p",null,[a("è¯·æŸ¥çœ‹ "),n("a",I,[a("camembert-base model card"),o(i)]),a("ï¼Œä½ èƒ½çœ‹åˆ°åœ¨ model card header ä¸­æœ‰å¦‚ä¸‹ä¿¡æ¯ï¼š")]),N,n("p",null,[a("å…·ä½“é…ç½®å¯æŸ¥çœ‹ "),n("a",O,[a("full model card specification"),o(i)]),a("ã€‚")])])}const U=d(m,[["render",B],["__file","Chapter4.html.vue"]]);export{U as default};
