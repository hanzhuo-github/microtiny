const e=JSON.parse('{"key":"v-3db5d214","path":"/ai/huggingface-nlp/section2/Chapter6.html","title":"6. ðŸ¤— Tokenizers åº“","lang":"zh-CN","frontmatter":{"lang":"zh-CN","title":"6. ðŸ¤— Tokenizers åº“","description":null,"article":false},"headers":[],"git":{"createdTime":1700236816000,"updatedTime":1700236816000,"contributors":[{"name":"Sunshine","email":"hanzhuosoul@gmail.com","commits":1}]},"readingTime":{"minutes":0.03,"words":10},"filePathRelative":"ai/huggingface-nlp/section2/Chapter6.md","localizedDate":"2023å¹´11æœˆ17æ—¥","excerpt":""}');export{e as data};
