const a=JSON.parse('{"key":"v-38a45680","path":"/ai/deep-rl/deep-q-learning.html","title":"Deep Q-learning","lang":"zh-CN","frontmatter":{"lang":"zh-CN","title":"Deep Q-learning","description":null,"article":false,"date":"2023-11-06T00:00:00.000Z","order":3},"headers":[{"level":2,"title":"1. The Deep Q-Network (DQN)","slug":"_1-the-deep-q-network-dqn","link":"#_1-the-deep-q-network-dqn","children":[{"level":3,"title":"DQN 的过程","slug":"dqn-的过程","link":"#dqn-的过程","children":[]}]},{"level":2,"title":"2. The Deep Q-Learning Algorithm","slug":"_2-the-deep-q-learning-algorithm","link":"#_2-the-deep-q-learning-algorithm","children":[{"level":3,"title":"2.1 Experience Replay","slug":"_2-1-experience-replay","link":"#_2-1-experience-replay","children":[]},{"level":3,"title":"2.2 Fixed Q-Target","slug":"_2-2-fixed-q-target","link":"#_2-2-fixed-q-target","children":[]},{"level":3,"title":"2.3 Double Deep Q-Learning","slug":"_2-3-double-deep-q-learning","link":"#_2-3-double-deep-q-learning","children":[]}]}],"git":{"createdTime":1700236816000,"updatedTime":1700236816000,"contributors":[{"name":"Sunshine","email":"hanzhuosoul@gmail.com","commits":1}]},"readingTime":{"minutes":4.84,"words":1453},"filePathRelative":"ai/deep-rl/deep-q-learning.md","localizedDate":"2023年11月6日","excerpt":"<p>Q-Learning 是 <em>tabular method</em>，It is not scalable. 当 state space 比较小时，我们可以使用之前的 Q-learning，训练 Q Table 来实现目标。当 state space 很大时（玩 Atari 游戏时，可能达到 <span class=\\"katex\\"><span class=\\"katex-mathml\\"><math xmlns=\\"http://www.w3.org/1998/Math/MathML\\"><semantics><mrow><mn>1</mn><msup><mn>0</mn><mn>9</mn></msup></mrow><annotation encoding=\\"application/x-tex\\">10^9</annotation></semantics></math></span><span class=\\"katex-html\\" aria-hidden=\\"true\\"><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.8141em;\\"></span><span class=\\"mord\\">1</span><span class=\\"mord\\"><span class=\\"mord\\">0</span><span class=\\"msupsub\\"><span class=\\"vlist-t\\"><span class=\\"vlist-r\\"><span class=\\"vlist\\" style=\\"height:0.8141em;\\"><span style=\\"top:-3.063em;margin-right:0.05em;\\"><span class=\\"pstrut\\" style=\\"height:2.7em;\\"></span><span class=\\"sizing reset-size6 size3 mtight\\"><span class=\\"mord mtight\\">9</span></span></span></span></span></span></span></span></span></span></span> 到 <span class=\\"katex\\"><span class=\\"katex-mathml\\"><math xmlns=\\"http://www.w3.org/1998/Math/MathML\\"><semantics><mrow><mn>1</mn><msup><mn>0</mn><mn>11</mn></msup></mrow><annotation encoding=\\"application/x-tex\\">10^{11}</annotation></semantics></math></span><span class=\\"katex-html\\" aria-hidden=\\"true\\"><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.8141em;\\"></span><span class=\\"mord\\">1</span><span class=\\"mord\\"><span class=\\"mord\\">0</span><span class=\\"msupsub\\"><span class=\\"vlist-t\\"><span class=\\"vlist-r\\"><span class=\\"vlist\\" style=\\"height:0.8141em;\\"><span style=\\"top:-3.063em;margin-right:0.05em;\\"><span class=\\"pstrut\\" style=\\"height:2.7em;\\"></span><span class=\\"sizing reset-size6 size3 mtight\\"><span class=\\"mord mtight\\"><span class=\\"mord mtight\\">11</span></span></span></span></span></span></span></span></span></span></span></span> 种状态之多），Q Table 就会很低效。在这种情况下，我们不再使用 Q 表，而是使用 Neural Network 来获取状态、根据该状态为每一个 action 估计 Q-value，这种方式就是 Deep Q-Learning。</p>"}');export{a as data};
