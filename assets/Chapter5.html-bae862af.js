import{_ as l}from"./plugin-vue_export-helper-c27b6911.js";import{r as i,o as c,c as u,d as a,e as n,f as s,w as p,b as t}from"./app-9011bd5d.js";const d={},r=t('<ol><li>ä» Hugging Face Hub ä¸ŠåŠ è½½æ•°æ®é›†</li><li>ä½¿ç”¨ <code>Dataset.map()</code> é¢„å¤„ç†æ•°æ®</li><li>åŠ è½½å¹¶è®¡ç®— metrics</li></ol><p>åœ¨æœ¬ç« å†…å®¹ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥äº†è§£ ğŸ¤— Datasets åº“ï¼Œä½ å°†èƒ½å¤Ÿå›ç­”ä»¥ä¸‹é—®é¢˜ï¼š</p><ul><li>æ•°æ®é›†ä¸åœ¨ hub ä¸Šåº”è¯¥æ€ä¹ˆåš</li><li>å¦‚ä½•å¯¹æ•°æ®é›†è¿›è¡Œåˆ‡ç‰‡ï¼ˆå¦‚æœä½ ç¡®å®éœ€è¦ä½¿ç”¨ Pandas æ€ä¹ˆåŠï¼‰</li><li>å¦‚æœä½ çš„æ•°æ®é›†å¾ˆå¤§ï¼Œä¼šæ’‘çˆ†ä½ çš„ RAM åº”è¯¥æ€ä¹ˆåŠ</li><li>Memory Mappingã€Apache Arrow æ˜¯ä»€ä¹ˆ</li><li>å¦‚ä½•åˆ›å»ºè‡ªå·±çš„æ•°æ®é›†å¹¶å°†å…¶æ¨è‡³ Hub</li></ul><h2 id="_1-å¤„ç†ä¸åœ¨-hugging-face-hub-ä¸Šçš„æ•°æ®é›†" tabindex="-1"><a class="header-anchor" href="#_1-å¤„ç†ä¸åœ¨-hugging-face-hub-ä¸Šçš„æ•°æ®é›†" aria-hidden="true">#</a> 1. å¤„ç†ä¸åœ¨ Hugging Face Hub ä¸Šçš„æ•°æ®é›†</h2><p>ğŸ¤— Datasets æä¾›äº†åŠ è½½æœ¬åœ°å’Œè¿œç¨‹æ•°æ®é›†çš„æ–¹æ³•ï¼Œæ”¯æŒä¸‹åˆ—æ ¼å¼ï¼š</p><table><thead><tr><th style="text-align:left;">Data format</th><th style="text-align:left;">Loading script</th><th style="text-align:left;">Example</th></tr></thead><tbody><tr><td style="text-align:left;">CSV &amp; TSV</td><td style="text-align:left;">csv</td><td style="text-align:left;">load_dataset(&quot;csv&quot;, data_files=&quot;my_file.csv&quot;)</td></tr><tr><td style="text-align:left;">Text files</td><td style="text-align:left;">text</td><td style="text-align:left;">load_dataset(&quot;text&quot;, data_files=&quot;my_file.txt&quot;)</td></tr><tr><td style="text-align:left;">JSON &amp; JSON Lines</td><td style="text-align:left;">json</td><td style="text-align:left;">load_dataset(&quot;json&quot;, data_files=&quot;my_file.jsonl&quot;)</td></tr><tr><td style="text-align:left;">Pickled DataFrames</td><td style="text-align:left;">pandas</td><td style="text-align:left;">load_dataset(&quot;pandas&quot;, data_files=&quot;my_dataframe.pkl&quot;)</td></tr></tbody></table><h3 id="_1-1-åŠ è½½æœ¬åœ°æ•°æ®é›†" tabindex="-1"><a class="header-anchor" href="#_1-1-åŠ è½½æœ¬åœ°æ•°æ®é›†" aria-hidden="true">#</a> 1.1 åŠ è½½æœ¬åœ°æ•°æ®é›†</h3>',7),k={href:"https://github.com/crux82/squad-it/",target:"_blank",rel:"noopener noreferrer"},m=t(`<details class="hint-container details"><summary>Ubuntu ä¸‹è½½å¹¶è§£å‹</summary><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token operator">!</span>wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-train.json.gz
<span class="token operator">!</span>wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-test.json.gz

<span class="token operator">!</span>gzip <span class="token parameter variable">-dkv</span> SQuAD_it-*.json.gz
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></details><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset

squad_it_dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">&quot;json&quot;</span><span class="token punctuation">,</span> data_files<span class="token operator">=</span><span class="token string">&quot;SQuAD_it-train.json&quot;</span><span class="token punctuation">,</span> field<span class="token operator">=</span><span class="token string">&quot;data&quot;</span><span class="token punctuation">)</span>
squad_it_dataset
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-text" data-ext="text"><pre class="language-text"><code>DatasetDict({
    train: Dataset({
        features: [&#39;paragraphs&#39;, &#39;title&#39;],
        num_rows: 442
    })
})
</code></pre></div><p>åŠ è½½æœ¬åœ°æ–‡ä»¶ä¼šåˆ›å»ºä¸€ä¸ªå¸¦æœ‰ <code>train</code> çš„ <code>DatasetDict</code> å¯¹è±¡ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸‹æ ‡æŸ¥çœ‹å‡ ä¸ªç¤ºä¾‹å¦‚ï¼š<code>squad_it_dataset[&quot;train&quot;][0]</code>ã€‚</p><p>å¦‚ä½•è·å¾—åŒæ—¶æœ‰ <code>train</code> å’Œ <code>test</code> çš„ <code>DatasetDict</code> å¯¹è±¡å‘¢ï¼Ÿ</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>data_files <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;SQuAD_it-train.json&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;test&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;SQuAD_it-test.json&quot;</span><span class="token punctuation">}</span>
squad_it_dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">&quot;json&quot;</span><span class="token punctuation">,</span> data_files<span class="token operator">=</span>data_files<span class="token punctuation">,</span> field<span class="token operator">=</span><span class="token string">&quot;data&quot;</span><span class="token punctuation">)</span>
squad_it_dataset
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-no-line-numbers line-numbers-mode" data-ext="no-line-numbers"><pre class="language-no-line-numbers"><code>DatasetDict({
    train: Dataset({
        features: [&#39;paragraphs&#39;, &#39;title&#39;],
        num_rows: 442
    })
    test: Dataset({
        features: [&#39;paragraphs&#39;, &#39;title&#39;],
        num_rows: 48
    })
})
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="hint-container tip"><p class="hint-container-title">æç¤º</p><p>data_files å‚æ•°å¾ˆçµæ´»ï¼Œå¯ä»¥æ˜¯å•ä¸ªæ–‡ä»¶è·¯å¾„ã€æ–‡ä»¶è·¯å¾„ listã€æ˜ å°„åç§°è·¯å¾„çš„å­—å…¸ï¼Œè¿˜å¯ä»¥ä½¿ç”¨ Unix shell çš„åŒ¹é…è§„åˆ™é€‰æ‹©å¤šæœ‰æ»¡è¶³è§„åˆ™çš„æ–‡ä»¶ï¼ˆå¦‚ <code>data_files=&quot;*.json&quot;</code> åŒ¹é…æ‰€æœ‰çš„ json æ–‡ä»¶ï¼‰ã€‚</p></div><p>ğŸ¤— Datasets çš„ loading script æ”¯æŒè‡ªåŠ¨è§£å‹ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥è·³è¿‡è‡ªå·±è§£å‹çš„è¿‡ç¨‹ï¼Œç›´æ¥ä½¿ç”¨ä¸‹é¢çš„ä»£ç åŠ è½½æ•°æ®ï¼š</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>data_files <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;SQuAD_it-train.json.gz&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;test&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;SQuAD_it-test.json.gz&quot;</span><span class="token punctuation">}</span>
squad_it_dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">&quot;json&quot;</span><span class="token punctuation">,</span> data_files<span class="token operator">=</span>data_files<span class="token punctuation">,</span> field<span class="token operator">=</span><span class="token string">&quot;data&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_1-2-åŠ è½½è¿œç¨‹æ•°æ®é›†" tabindex="-1"><a class="header-anchor" href="#_1-2-åŠ è½½è¿œç¨‹æ•°æ®é›†" aria-hidden="true">#</a> 1.2 åŠ è½½è¿œç¨‹æ•°æ®é›†</h3><p>å°† <code>data_files</code> è®¾ç½®ä¸º url å³å¯ã€‚</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>url <span class="token operator">=</span> <span class="token string">&quot;https://github.com/crux82/squad-it/raw/master/&quot;</span>
data_files <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">&quot;train&quot;</span><span class="token punctuation">:</span> url <span class="token operator">+</span> <span class="token string">&quot;SQuAD_it-train.json.gz&quot;</span><span class="token punctuation">,</span>
    <span class="token string">&quot;test&quot;</span><span class="token punctuation">:</span> url <span class="token operator">+</span> <span class="token string">&quot;SQuAD_it-test.json.gz&quot;</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>
squad_it_dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">&quot;json&quot;</span><span class="token punctuation">,</span> data_files<span class="token operator">=</span>data_files<span class="token punctuation">,</span> field<span class="token operator">=</span><span class="token string">&quot;data&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_2-åˆ‡ç‰‡" tabindex="-1"><a class="header-anchor" href="#_2-åˆ‡ç‰‡" aria-hidden="true">#</a> 2. åˆ‡ç‰‡</h2><h3 id="_2-1-slicing-and-dicing-æ•°æ®" tabindex="-1"><a class="header-anchor" href="#_2-1-slicing-and-dicing-æ•°æ®" aria-hidden="true">#</a> 2.1 Slicing and dicing æ•°æ®</h3>`,15),g=a("code",null,"Dataset",-1),v=a("code",null,"DatasetDict",-1),h=a("code",null,"Dataset.map()",-1),b={href:"https://archive.ics.uci.edu/dataset/462/drug+review+dataset+drugs+com",target:"_blank",rel:"noopener noreferrer"},y=t(`<p>TSV æ˜¯ CSV çš„å˜ä½“ï¼Œå®ƒå’Œ CSV çš„åŒºåˆ«åœ¨äº CSV ç”¨é€—å·ä½œä¸ºåˆ†å‰²ç¬¦ï¼Œè€Œ TSV ä½¿ç”¨åˆ¶è¡¨ç¬¦ä½œä¸ºåˆ†éš”ç¬¦ã€‚æ‰€ä»¥æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ csv åŠ è½½çš„æ–¹å¼å¹¶æŒ‡å®š delimiterã€‚</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset

data_files <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;drugLibTrain_raw.tsv&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;test&quot;</span><span class="token punctuation">:</span> <span class="token string">&quot;drugLibTest_raw.tsv&quot;</span><span class="token punctuation">}</span>
drug_dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">&quot;csv&quot;</span><span class="token punctuation">,</span> data_files<span class="token operator">=</span>data_files<span class="token punctuation">,</span> delimiter<span class="token operator">=</span><span class="token string">&quot;\\t&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>æˆ‘ä»¬å¯ä»¥æŠ½å–ä¸€äº›æ ·æœ¬æ¥è§‚å¯Ÿï¼Œä»¥å¯¹æ•°æ®æœ‰ä¸€ä¸ªç›´è§‚çš„è®¤è¯†ã€‚å¯ä»¥ä½¿ç”¨ <code>Dataset.shuffle()</code> å’Œ <code>Dataset.select()</code> æ¥éšæœºæŠ½å–æ ·æœ¬ã€‚</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>drug_sample <span class="token operator">=</span> drug_dataset<span class="token punctuation">[</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># é€‰å–å‰é¢å‡ ä¸ªæ ·æœ¬</span>
drug_sample<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><details class="hint-container details"><summary>è¿è¡Œç»“æœ</summary><div class="language-text" data-ext="text"><pre class="language-text"><code>{&#39;Unnamed: 0&#39;: [1468, 3422, 1444],
 &#39;urlDrugName&#39;: [&#39;cymbalta&#39;, &#39;tazorac&#39;, &#39;tirosint&#39;],
 &#39;rating&#39;: [9, 5, 4],
 &#39;effectiveness&#39;: [&#39;Highly Effective&#39;,
  &#39;Moderately Effective&#39;,
  &#39;Moderately Effective&#39;],
 &#39;sideEffects&#39;: [&#39;No Side Effects&#39;,
  &#39;Severe Side Effects&#39;,
  &#39;Moderate Side Effects&#39;],
 &#39;condition&#39;: [&#39;sever depression&#39;,
  &#39;acne&#39;,
  &#39;thyroid/total thyroidectomy due to cancer&#39;],
 &#39;benefitsReview&#39;: [&quot;This medication saved my life. The depression had gotten so sever that I was unable to function properly. It has made me feel like a &#39;real&#39; person again. It has not done much for the anxiety, panic, or OCD. The Xanax helps with that area. I will be going to the psychiatrist in 2 weeks for the anxiety, panic, and OCD. Hoping to stay on the Cymbalta. I was on Lexapro 30mg from 2000-2006. Then switched to Celexa (cost reasons) 60mg from 2007-2008. The Celexa just about costed me my life. It was ineffective for the Depression. Try not to take Celexa for cost reasons, Lexapro shows much more promise in its effectiveness.&quot;,
  &#39;It exfoliated my skin.&#39;,
  &#39;I started taking Tirosint 125mcg 6 weeks ago due to a gluten and caseine allergy. I previously was taking synthroid however, the company couldnt verify the inactive ingredients. So to avoid gluten, caseine, and some really nasty anxiety symptms I switched to the Tirosint. \\r\\r\\n\\r\\r\\nThe anxiety symptoms subsided from 1 attack per day to none. This was great!, but then new symptoms started after three weeks.&#39;],
 &#39;sideEffectsReview&#39;: [&#39;Weight gain, which is to be expected when you &quot;feel better&quot;&#39;,
  &#39;My skin became extremely dry, irritated, red, and would peel.&#39;,
  &#39;I felt dperessed, tired and very sore. My finger joints hurt so bad and to the touch. My back, and legs ached. Then my lower legs, ankles and feet started to swell. it is so bad that I cannot walk upon waking in the morning. If Im on my feet for more than an hour I have to elevate my legs due to the pain and swelling. I also gained alot of weight 8lbs. I\\&#39;m a healthy 37 year old woman, I am active with two small boys, and eat an extremley healthy diet due to my Celiacs and Caseine allergies. \\r\\r\\n\\r\\r\\nI recently had my blood levels checked and to my surprise I was taking way too much Tirosint. My Endo said that the swelling and pain wasnt from the Tirosint and that I should see my Primary doctor...REALLY??  I was shocked due to my &quot;hypo&quot; symptoms. Im thinking of returning to Synthroid and switching doctors...&#39;],
 &#39;commentsReview&#39;: [&#39;Depression and Anxiety&#39;,
  &#39;Use once daily, at night.  Wash face, use toner and leave to dry (10 minutes).  Then apply pea size amount of cream all over face, excluding eye area.  Let soak in (15 minutes), then layer with moisturizer.  Must wear sunscreen daily.&#39;,
  &#39;125 mcg Tirosint per day and doubled on Sat and Sun. \\r\\r\\n\\r\\r\\nListen to your body and be persistent with your doctors.&#39;]}
</code></pre></div></details><p><code>Dataset.select()</code> éœ€è¦ä¼ å…¥ä¸€ä¸ªå¯è¿­ä»£çš„ç´¢å¼•ï¼Œè¿™é‡Œæˆ‘ä»¬ä¼ å…¥äº† <code>range(1000)</code> ä»éšæœºæ‰“ä¹±çš„æ•°æ®é›†ä¸­é€‰å–å‰ 1000 ä¸ªæ ·æœ¬ã€‚æˆ‘ä»¬å¯ä»¥çœ‹å‡ºæ•°æ®é›†çš„ä¸€äº›ç‰¹ç‚¹äº†ï¼š</p><ul><li><code>Unnamed: 0</code>: å¯èƒ½æ˜¯æ‚£è€…çš„ ID</li><li><code>condition</code>: æè¿°å¥åº·çŠ¶å†µçš„æ ‡ç­¾ï¼Œæœ‰å¤§å†™æœ‰å°å†™</li><li>å„ç±» review: é•¿çŸ­ä¸ä¸€ï¼Œæ··æœ‰ Python è¡Œåˆ†éš”ç¬¦ï¼ˆ\\r\\nï¼‰ã€html å­—ç¬¦ç¼–ç ï¼ˆè§ ğŸ¤— å®˜æ–¹ç¤ºä¾‹ï¼Œå¦‚<code>&amp;#039;</code>ï¼‰</li></ul><p>ä¸‹é¢æˆ‘ä»¬éªŒè¯ä¸€ä¸‹ Unnamed 0 æ˜¯æ‚£è€… ID çš„çŒœæƒ³ï¼Œè¿™é‡Œä¼šç”¨åˆ° <code>Dataset.unique()</code>ï¼š</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">for</span> split <span class="token keyword">in</span> drug_dataset<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">assert</span> <span class="token builtin">len</span><span class="token punctuation">(</span>drug_dataset<span class="token punctuation">[</span>split<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token builtin">len</span><span class="token punctuation">(</span>drug_dataset<span class="token punctuation">[</span>split<span class="token punctuation">]</span><span class="token punctuation">.</span>unique<span class="token punctuation">(</span><span class="token string">&quot;Unnamed: 0&quot;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>ä¸Šé¢çš„ä»£ç æ²¡æŠ›å‡º <code>AssertionError</code>ï¼Œçœ‹æ¥æ˜¯æ‚£è€… ID çš„è¿™ä¸ªæƒ³æ³•æ˜¯æ­£ç¡®çš„ã€‚æˆ‘ä»¬å°†è¯¥åˆ—é‡å‘½åä¸º patient_idï¼Œè¿™é‡Œä¼šç”¨åˆ° <code>DatasetDict.rename_column()</code>:</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>drug_dataset <span class="token operator">=</span> drug_dataset<span class="token punctuation">.</span>rename_column<span class="token punctuation">(</span>
    original_column_name<span class="token operator">=</span><span class="token string">&quot;Unnamed: 0&quot;</span><span class="token punctuation">,</span> new_column_name<span class="token operator">=</span><span class="token string">&quot;patient_id&quot;</span>
<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>æˆ‘ä»¬ä½¿ç”¨ <code>Dataset.map()</code> æ ‡å‡†åŒ–æ‰€æœ‰çš„ conditionï¼š</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">lowercase_condition</span><span class="token punctuation">(</span>example<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token string">&quot;condition&quot;</span><span class="token punctuation">:</span> example<span class="token punctuation">[</span><span class="token string">&quot;condition&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>


drug_dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>lowercase_condition<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-text" data-ext="text"><pre class="language-text"><code>AttributeError: &#39;NoneType&#39; object has no attribute &#39;lower&#39;
</code></pre></div><p>çœ‹æ¥æˆ‘ä»¬è¿˜éœ€è¦æŠŠ condition ä¸º None çš„æ•°æ®è¿‡æ»¤æ‰ï¼ˆä½¿ç”¨ <code>Dataset.filter()</code>ï¼‰ï¼š</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>drug_dataset <span class="token operator">=</span> drug_dataset<span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token string">&quot;condition&quot;</span><span class="token punctuation">]</span> <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="_2-2-åˆ›å»ºæ–°åˆ—" tabindex="-1"><a class="header-anchor" href="#_2-2-åˆ›å»ºæ–°åˆ—" aria-hidden="true">#</a> 2.2 åˆ›å»ºæ–°åˆ—</h3><p>åœ¨å¤„ç† review å­—æ®µæ—¶ï¼Œæœ€å¥½æ˜¯è¦ç»Ÿè®¡ä¸€ä¸‹å­—æ•°ã€‚æˆ‘ä»¬å°±ç®€å•åŸºäºç©ºæ ¼æ¥è¿›è¡Œè¯æ•°ç»Ÿè®¡ã€‚</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">compute_review_length</span><span class="token punctuation">(</span>example<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">{</span><span class="token string">&quot;benefit_review_length&quot;</span><span class="token punctuation">:</span> <span class="token builtin">len</span><span class="token punctuation">(</span>example<span class="token punctuation">[</span><span class="token string">&quot;benefitsReview&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span>

drug_dataset <span class="token operator">=</span> drug_dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>compute_review_length<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>è¿™æ ·ï¼Œæˆ‘ä»¬å°±å¢åŠ äº† benefit_review_length åˆ—ã€‚æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨ <code>Dataset.sort()</code> ä»¥è¯¥åˆ—ä¸ºåŸºå‡†åšæ’åº</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>drug_datasets<span class="token punctuation">[</span><span class="token string">&quot;train&quot;</span><span class="token punctuation">]</span><span class="token punctuation">.</span>sort<span class="token punctuation">(</span><span class="token string">&quot;benefit_review_length&quot;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><div class="hint-container tip"><p class="hint-container-title">\`Dataset.add_column()\`</p><p>æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨ <code>Dataset.add_column()</code> å¢åŠ åˆ—ã€‚å¯ä»¥ä¼ å…¥ Python list æˆ– numpyã€‚</p></div><p>review çš„è¯æ•°è¾ƒå°‘æ—¶ï¼ˆæç«¯æƒ…å†µæ¯”å¦‚åªæœ‰ä¸€ä¸ªè¯ï¼‰å¯¹äºé¢„æµ‹æ²¡æœ‰æä¾›ç›¸å¯¹æœ‰ç”¨çš„ä¿¡æ¯ã€‚ä¸‹é¢æˆ‘å°†ä½¿ç”¨ Dataset.filter() å°†å°‘äº 30 ä¸ªè¯çš„ review å»æ‰ã€‚</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>drug_dataset <span class="token operator">=</span> drug_dataset<span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token string">&quot;benefit_review_length&quot;</span><span class="token punctuation">]</span> <span class="token operator">&gt;</span> <span class="token number">30</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>drug_dataset<span class="token punctuation">.</span>num_rows<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-text" data-ext="text"><pre class="language-text"><code>{&#39;train&#39;: 1445, &#39;test&#39;: 473}
</code></pre></div><p>review ä¸­è¿˜æœ‰ä¸€äº› html ç¼–ç ï¼Œå¯ä»¥ä½¿ç”¨ Python çš„ html module æ¥è§£ç ï¼š</p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">import</span> html

text <span class="token operator">=</span> <span class="token string">&quot;I&amp;#039;m a transformer called BERT&quot;</span>
html<span class="token punctuation">.</span>unescape<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-text" data-ext="text"><pre class="language-text"><code>&quot;I&#39;m a transformer called BERT&quot;
</code></pre></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>drug_dataset <span class="token operator">=</span> drug_dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token punctuation">{</span> <span class="token string">&quot;benefitsReview&quot;</span><span class="token punctuation">:</span> html<span class="token punctuation">.</span>unescape<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token string">&quot;benefitsReview&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h3 id="_2-3-map-æ–¹æ³•" tabindex="-1"><a class="header-anchor" href="#_2-3-map-æ–¹æ³•" aria-hidden="true">#</a> 2.3 <code>map()</code> æ–¹æ³•</h3><p><code>Dataset.map()</code> æœ‰ä¸€ä¸ªå‚æ•°æ˜¯ <code>batched</code>ã€‚å°†å…¶è®¾ä¸º True åï¼Œmap å‡½æ•°å°†ä¸€æ¬¡å¤„ç†å¤šä¸ªæ•°æ®ï¼ˆæˆä¸ºä¸€æ‰¹ a batchï¼‰ï¼Œbatch size å¯ä»¥é…ç½®ï¼Œé»˜è®¤æƒ…å†µä¸‹ä¸º 1000.</p>`,31);function _(f,q){const e=i("RouterLink"),o=i("ExternalLinkIcon");return c(),u("div",null,[a("p",null,[n("åœ¨"),s(e,{to:"/ai/huggingface/section1/Chapter3.html"},{default:p(()=>[n("ç¬¬ä¸‰ç« ")]),_:1}),n("ä¸­æˆ‘ä»¬åˆæ­¥ä½“éªŒäº† ğŸ¤— Datasets åº“ï¼Œäº†è§£ fine-tune çš„åŸºæœ¬æ­¥éª¤ï¼š")]),r,a("p",null,[n("æˆ‘ä»¬ä½¿ç”¨ "),a("a",k,[n("SQuAD-it dataset"),s(o)]),n("ï¼Œå®ƒæ˜¯å¤§è§„æ¨¡æ„å¤§åˆ©è¯­é—®ç­”æ•°æ®é›†ã€‚")]),m,a("p",null,[n("å’Œ Pandas ç±»ä¼¼ï¼ŒğŸ¤— Datasets ä¹Ÿæä¾›äº†ä¸€äº›å‡½æ•°å¤„ç† "),g,n(" å’Œ "),v,n(" å¯¹è±¡ã€‚åœ¨"),s(e,{to:"/ai/huggingface/section1/Chapter3.html"},{default:p(()=>[n("ç¬¬ä¸‰ç« ")]),_:1}),n("ä¸­æˆ‘ä»¬ä»‹ç»äº† "),h,n("ï¼Œæœ¬ç« æˆ‘ä»¬å°†ä»‹ç»å…¶ä»–å‡½æ•°ã€‚")]),a("p",null,[n("æ¥ä¸‹æ¥æˆ‘ä»¬ä½¿ç”¨çš„æ•°æ®é›†ä¸º "),a("a",b,[n("Drug Review Dataset"),s(o)]),n("ã€‚")]),y])}const D=l(d,[["render",_],["__file","Chapter5.html.vue"]]);export{D as default};
