import{_ as n}from"./plugin-vue_export-helper-c27b6911.js";import{r as m,o as e,c as i,b as s,d as a,e as r,f as l}from"./app-1e7cdb66.js";const p="/images/ml/drl/RL_process.jpg",c={},h=s("p",null,"深度强化学习（Deep Reinforcement Learning）是机器学习的一种，用于训练智能代理（Agent）在未知环境中通过试错学习来采取最佳行动以实现特定目标。",-1),o=s("p",null,"深度学习背后的思想是，一个代理（一种人工智能）通过与环境的互动（通过试错）并根据执行动作后获得的奖励（正面或负面的反馈）来学习。",-1),g={class:"hint-container info"},u=s("p",{class:"hint-container-title"},"相关信息",-1),d={href:"http://incompleteideas.net/book/RLbook2020.pdf",target:"_blank",rel:"noopener noreferrer"},y=l('<p>下面将介绍强化学习相关的概念，而深度强化学习就是将 deep neural networks 应用于强化学习问题中。</p><h2 id="_1-rl-process" tabindex="-1"><a class="header-anchor" href="#_1-rl-process" aria-hidden="true">#</a> 1. RL Process</h2><figure><img src="'+p+'" alt="" width="600" tabindex="0"><figcaption></figcaption></figure><p>RL 循环输出一系列的 <strong>state</strong>, <strong>action</strong>, <strong>reward</strong> 和 <strong>next state</strong>。</p>',4),v=s("ul",null,[s("li",null,[s("p",null,[s("strong",null,"Reward Hypothesis"),a(": Agent 的目标是最大化累积奖励，即 "),s("strong",null,"expected return"),a("。")])]),s("li",null,[s("p",null,[s("strong",null,"Markov Decision Process (MDP)"),a("：Agent "),s("strong",null,"只需要当前的状态"),a("来决定采取什么行动，而不需要考虑之前所有状态和行动的历史")])]),s("li",null,[s("p",null,[s("strong",null,"Observations/States Space"),a("：这是 Agent 从环境中获取的信息。在视频游戏中，可以是一帧图片。")]),s("ul",null,[s("li",null,"State s: 对世界状态的完整描述。比如象棋游戏中我们可以获得整个棋盘信息。"),s("li",null,"Observation o: 是状态的部分描述。比如超级玛丽中，我们只能看到玩家附近的地图。")])]),s("li",null,[s("p",null,[s("strong",null,"Action Space"),a("：环境中所有可能的 actions 的集合")]),s("ul",null,[s("li",null,"Discrete space: 可能的 actions 的数量有限。比如超级玛丽中，actions 只有 ↑↓←→"),s("li",null,"Continuous space: 可能的 actions 的数量无限。比如自动驾驶")])]),s("li",null,[s("p",null,[s("strong",null,"Reward & discounting"),a("：奖励在 RL 中至关重要，它是 Agent 的卫衣反馈，通过奖励可以知道采取的行动是好是坏。")]),s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"R"),s("mo",{stretchy:"false"},"("),s("mi",null,"τ"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("msub",null,[s("mi",null,"r"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"1")])]),s("mo",null,"+"),s("msub",null,[s("mi",null,"r"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"2")])]),s("mo",null,"+"),s("msub",null,[s("mi",null,"r"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"3")])]),s("mo",null,"+"),s("msub",null,[s("mi",null,"r"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"4")])]),s("mo",null,"+"),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"."),s("mo",null,"="),s("munderover",null,[s("mo",null,"∑"),s("mrow",null,[s("mi",null,"k"),s("mo",null,"="),s("mn",null,"0")]),s("mi",{mathvariant:"normal"},"∞")]),s("msub",null,[s("mi",null,"r"),s("mrow",null,[s("mi",null,"r"),s("mo",null,"+"),s("mi",null,"k"),s("mo",null,"+"),s("mn",null,"1")])])]),s("annotation",{encoding:"application/x-tex"}," R(\\tau) = r_{t+1} + r_{t+2} + r_{t+3} + r_{t+4} + ... = \\sum_{k=0}^\\infty r_{r+k+1} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.1132em"}},"τ"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7917em","vertical-align":"-0.2083em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7917em","vertical-align":"-0.2083em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"2")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7917em","vertical-align":"-0.2083em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"3")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7917em","vertical-align":"-0.2083em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"4")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.3669em"}}),s("span",{class:"mord"},"..."),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.9535em","vertical-align":"-1.3021em"}}),s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.6514em"}},[s("span",{style:{top:"-1.8479em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k"),s("span",{class:"mrel mtight"},"="),s("span",{class:"mord mtight"},"0")])])]),s("span",{style:{top:"-3.05em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",null,[s("span",{class:"mop op-symbol large-op"},"∑")])]),s("span",{style:{top:"-4.3em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"∞")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3021em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])])])])])])]),s("p",null,[a("但我们通常不会这样直接加和。较早出现的奖励比远期的奖励更有可能发生、更可预测。于是我们定义了 discount（用 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"γ")]),s("annotation",{encoding:"application/x-tex"},"\\gamma")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.625em","vertical-align":"-0.1944em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ")])])]),a(" 表示），该值在 0 到 1 之间（大部分时候是0.95 到 0.99）.")]),s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"R"),s("mo",{stretchy:"false"},"("),s("mi",null,"τ"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("msub",null,[s("mi",null,"r"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"1")])]),s("mo",null,"+"),s("mi",null,"γ"),s("msub",null,[s("mi",null,"r"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"2")])]),s("mo",null,"+"),s("msup",null,[s("mi",null,"γ"),s("mn",null,"2")]),s("msub",null,[s("mi",null,"r"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"3")])]),s("mo",null,"+"),s("msup",null,[s("mi",null,"γ"),s("mn",null,"3")]),s("msub",null,[s("mi",null,"r"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"4")])]),s("mo",null,"+"),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"."),s("mo",null,"="),s("munderover",null,[s("mo",null,"∑"),s("mrow",null,[s("mi",null,"k"),s("mo",null,"="),s("mn",null,"0")]),s("mi",{mathvariant:"normal"},"∞")]),s("msup",null,[s("mi",null,"γ"),s("mi",null,"k")]),s("msub",null,[s("mi",null,"r"),s("mrow",null,[s("mi",null,"r"),s("mo",null,"+"),s("mi",null,"k"),s("mo",null,"+"),s("mn",null,"1")])])]),s("annotation",{encoding:"application/x-tex"}," R(\\tau) = r_{t+1} + \\gamma r_{t+2} + \\gamma ^{2}r_{t+3} + \\gamma ^{3}r_{t+4} + ... = \\sum_{k=0}^\\infty \\gamma ^{k}r_{r+k+1} ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal",style:{"margin-right":"0.1132em"}},"τ"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7917em","vertical-align":"-0.2083em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.7917em","vertical-align":"-0.2083em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"2")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0724em","vertical-align":"-0.2083em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"3")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0724em","vertical-align":"-0.2083em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"3")])])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"4")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.3669em"}}),s("span",{class:"mord"},"..."),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"2.9535em","vertical-align":"-1.3021em"}}),s("span",{class:"mop op-limits"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.6514em"}},[s("span",{style:{top:"-1.8479em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k"),s("span",{class:"mrel mtight"},"="),s("span",{class:"mord mtight"},"0")])])]),s("span",{style:{top:"-3.05em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",null,[s("span",{class:"mop op-symbol large-op"},"∑")])]),s("span",{style:{top:"-4.3em","margin-left":"0em"}},[s("span",{class:"pstrut",style:{height:"3.05em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},"∞")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"1.3021em"}},[s("span")])])])]),s("span",{class:"mspace",style:{"margin-right":"0.1667em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8991em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k")])])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3361em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0278em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.02778em"}},"r"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03148em"}},"k"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])])])])])])])])],-1),b=l('<h2 id="_2-任务类型" tabindex="-1"><a class="header-anchor" href="#_2-任务类型" aria-hidden="true">#</a> 2. 任务类型</h2><h4 id="类型-1-episodic-task" tabindex="-1"><a class="header-anchor" href="#类型-1-episodic-task" aria-hidden="true">#</a> 类型 1：episodic task</h4><p>在这种情况下，有初始状态和终止状态。即创建了一个&quot;episode&quot;：一个包含了 States、Actions、Rewards 和 new States 的序列。</p><h4 id="类型-2-continuing-task" tabindex="-1"><a class="header-anchor" href="#类型-2-continuing-task" aria-hidden="true">#</a> 类型 2：continuing task</h4><p>即没有终止状态的情况。Agent 必须学会如何选择最佳的 actions 并同时与环境互动。</p><h2 id="_3-the-exploration-exploitation-trade-off" tabindex="-1"><a class="header-anchor" href="#_3-the-exploration-exploitation-trade-off" aria-hidden="true">#</a> 3. The Exploration/Exploitation trade-off</h2><ul><li>Exploration: 通过随机 actions 来探索环境，以获取更多关于环境的信息。</li><li>Exploitation: 利用已知信息最大化奖励。</li></ul><p>强化学习中 Agent 的目标是最大化 expected cumulative reward。然而，我们可能会陷入一个常见的陷阱中。</p><p>这个陷阱是探索与利用之间的权衡问题。如果智能体过于探索，它可能会错失机会，浪费时间并且无法获得足够的奖励。如果它过于利用，它可能会错过更好的策略，并且无法达到最佳性能。因此，强化学习算法需要智能地决定何时以探索为主，何时以利用为主，以便在学习过程中不断改进其策略。</p><h2 id="_4-rl-问题的两种主要方法" tabindex="-1"><a class="header-anchor" href="#_4-rl-问题的两种主要方法" aria-hidden="true">#</a> 4. RL 问题的两种主要方法</h2>',10),x=s("ul",null,[s("li",null,[s("p",null,[s("strong",null,[a("The policy "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"π")]),s("annotation",{encoding:"application/x-tex"},"\\pi")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"π")])])])]),a(": "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("mi",null,"π")]),s("annotation",{encoding:"application/x-tex"},"\\pi")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"π")])])]),a(" 相当于 Agent 的大脑，它是一个函数，会告诉 Agent 根据现在的 State 应该采取哪种 action，即它确定了某一时刻下 Agent 的行为。")]),s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"S"),s("mi",null,"t"),s("mi",null,"a"),s("mi",null,"t"),s("mi",null,"e"),s("mo",null,"→"),s("mi",null,"π"),s("mo",{stretchy:"false"},"("),s("mi",null,"S"),s("mi",null,"t"),s("mi",null,"a"),s("mi",null,"t"),s("mi",null,"e"),s("mo",{stretchy:"false"},")"),s("mo",null,"→"),s("mi",null,"A"),s("mi",null,"c"),s("mi",null,"t"),s("mi",null,"i"),s("mi",null,"o"),s("mi",null,"n")]),s("annotation",{encoding:"application/x-tex"}," State \\rightarrow \\pi (State) \\rightarrow Action ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal"},"St"),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"→"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"π"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"St"),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"e"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"→"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6833em"}}),s("span",{class:"mord mathnormal"},"A"),s("span",{class:"mord mathnormal"},"c"),s("span",{class:"mord mathnormal"},"t"),s("span",{class:"mord mathnormal"},"i"),s("span",{class:"mord mathnormal"},"o"),s("span",{class:"mord mathnormal"},"n")])])])])]),s("p",null,[a("policy 是我们要学的函数，我们的目标就是找到最佳的 policy "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"π"),s("mo",{lspace:"0em",rspace:"0em"},"∗")])]),s("annotation",{encoding:"application/x-tex"},"\\pi ^ {*}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6887em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"π"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6887em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"∗")])])])])])])])])])])]),a("，即当 agent 按照它的计算会得到最大的 expected return。")]),s("p",null,[a("训练得到 "),s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[s("semantics",null,[s("mrow",null,[s("msup",null,[s("mi",null,"π"),s("mo",{lspace:"0em",rspace:"0em"},"∗")])]),s("annotation",{encoding:"application/x-tex"},"\\pi ^ {*}")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.6887em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"π"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.6887em"}},[s("span",{style:{top:"-3.063em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"∗")])])])])])])])])])])]),a(" 的方法：")]),s("ul",null,[s("li",null,"Policy-Based（直接）：给定当前的状态，直接告诉 agent 采取哪个 action"),s("li",null,"Value-Based（间接）：让 agent 学哪种 State 更有价值，然后选择能达到更有价值的 states 的 action")])])],-1),k=s("h4",{id:"方法-1-策略方法-policy-based",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#方法-1-策略方法-policy-based","aria-hidden":"true"},"#"),a(" 方法 1：策略方法（Policy-Based）")],-1),z=s("p",null,"核心思想是直接学习一个策略函数（policy function）。策略函数定义了在每个状态下应该采取的最佳行动，或者它可以定义一个在该状态下可能行动的概率分布。",-1),w=s("ul",null,[s("li",null,[a("Deterministic: 对于给定 state 总是返回同一个 action"),s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"a"),s("mo",null,"="),s("mi",null,"π"),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{stretchy:"false"},")")]),s("annotation",{encoding:"application/x-tex"}," a = \\pi (s) ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.4306em"}}),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"π"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mclose"},")")])])])])])]),s("li",null,[a("Stochastic: 会输出一个关于可能行动的概率分布。在相同的状态下，随机性策略可以选择不同的行动，具有一定的随机性。"),s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("mi",null,"π"),s("mo",{stretchy:"false"},"("),s("mi",null,"a"),s("mi",{mathvariant:"normal"},"∣"),s("mi",null,"s"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("mi",null,"P"),s("mo",{stretchy:"false"},"["),s("mi",null,"A"),s("mi",{mathvariant:"normal"},"∣"),s("mi",null,"s"),s("mo",{stretchy:"false"},"]")]),s("annotation",{encoding:"application/x-tex"}," \\pi (a|s) = P[A|s] ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"π"),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"a"),s("span",{class:"mord"},"∣"),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.13889em"}},"P"),s("span",{class:"mopen"},"["),s("span",{class:"mord mathnormal"},"A"),s("span",{class:"mord"},"∣"),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mclose"},"]")])])])])])])],-1),_=s("h4",{id:"方法-2-value-based-方法",tabindex:"-1"},[s("a",{class:"header-anchor",href:"#方法-2-value-based-方法","aria-hidden":"true"},"#"),a(" 方法 2：Value-Based 方法")],-1),f=s("p",null,"不直接学策略函数，而是学一个值函数（value function）。这个值函数将状态（State）映射到在该状态下的期望价值（Expected Value）。这里的价值是指在给定状态下，如果 Agent 按照我们的策略行动，它可以获得的期望折扣回报（Expected Discounted Return）。",-1),M=s("p",{class:"katex-block"},[s("span",{class:"katex-display"},[s("span",{class:"katex"},[s("span",{class:"katex-mathml"},[s("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[s("semantics",null,[s("mrow",null,[s("msub",null,[s("mi",null,"v"),s("mi",null,"π")]),s("mo",{stretchy:"false"},"("),s("mi",null,"s"),s("mo",{stretchy:"false"},")"),s("mo",null,"="),s("msub",null,[s("mi",null,"E"),s("mi",null,"π")]),s("mo",{stretchy:"false"},"["),s("msub",null,[s("mi",null,"R"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"1")])]),s("mo",null,"+"),s("mi",null,"γ"),s("msub",null,[s("mi",null,"R"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"2")])]),s("mo",null,"+"),s("msup",null,[s("mi",null,"γ"),s("mn",null,"2")]),s("msub",null,[s("mi",null,"R"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"3")])]),s("mo",null,"+"),s("msup",null,[s("mi",null,"γ"),s("mn",null,"3")]),s("msub",null,[s("mi",null,"R"),s("mrow",null,[s("mi",null,"t"),s("mo",null,"+"),s("mn",null,"4")])]),s("mo",null,"+"),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"."),s("mi",{mathvariant:"normal"},"∣"),s("msub",null,[s("mi",null,"S"),s("mi",null,"t")]),s("mo",null,"="),s("mi",null,"s"),s("mo",{stretchy:"false"},"]")]),s("annotation",{encoding:"application/x-tex"}," v_\\pi(s) = E_\\pi[R_{t+1} + \\gamma R_{t+2} + \\gamma ^{2}R_{t+3} + \\gamma ^{3}R_{t+4} + ...| S_t=s] ")])])]),s("span",{class:"katex-html","aria-hidden":"true"},[s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.03588em"}},"v"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0359em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"π")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"("),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mclose"},")"),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"E"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.1514em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0576em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight",style:{"margin-right":"0.03588em"}},"π")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mopen"},"["),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"1")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"0.8917em","vertical-align":"-0.2083em"}}),s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"2")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0724em","vertical-align":"-0.2083em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"2")])])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"3")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1.0724em","vertical-align":"-0.2083em"}}),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05556em"}},"γ"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.8641em"}},[s("span",{style:{top:"-3.113em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mtight"},"3")])])])])])])])]),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.00773em"}},"R"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.3011em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0077em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mtight"},[s("span",{class:"mord mathnormal mtight"},"t"),s("span",{class:"mbin mtight"},"+"),s("span",{class:"mord mtight"},"4")])])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2083em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}}),s("span",{class:"mbin"},"+"),s("span",{class:"mspace",style:{"margin-right":"0.2222em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord"},"...∣"),s("span",{class:"mord"},[s("span",{class:"mord mathnormal",style:{"margin-right":"0.05764em"}},"S"),s("span",{class:"msupsub"},[s("span",{class:"vlist-t vlist-t2"},[s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.2806em"}},[s("span",{style:{top:"-2.55em","margin-left":"-0.0576em","margin-right":"0.05em"}},[s("span",{class:"pstrut",style:{height:"2.7em"}}),s("span",{class:"sizing reset-size6 size3 mtight"},[s("span",{class:"mord mathnormal mtight"},"t")])])]),s("span",{class:"vlist-s"},"​")]),s("span",{class:"vlist-r"},[s("span",{class:"vlist",style:{height:"0.15em"}},[s("span")])])])])]),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}}),s("span",{class:"mrel"},"="),s("span",{class:"mspace",style:{"margin-right":"0.2778em"}})]),s("span",{class:"base"},[s("span",{class:"strut",style:{height:"1em","vertical-align":"-0.25em"}}),s("span",{class:"mord mathnormal"},"s"),s("span",{class:"mclose"},"]")])])])])],-1),R=s("p",null,"具体来说，价值函数用于衡量在不同状态下的优劣，这有助于代理决定在哪个状态采取行动，以获得最大的长期回报。这种方法的核心思想是：代理通过学习状态的价值来评估每个状态的好坏，然后根据这些值来决定在哪个状态采取行动，即选择具有最高价值的状态作为下一步的目标。",-1);function A(L,S){const t=m("ExternalLinkIcon");return e(),i("div",null,[h,o,s("div",g,[u,s("p",null,[s("a",d,[a("Reinforcement Learning: An Introduction, Richard Sutton and Andrew G. Barto"),r(t)])])]),y,v,b,x,k,z,w,_,f,M,R])}const P=n(c,[["render",A],["__file","index.html.vue"]]);export{P as default};
