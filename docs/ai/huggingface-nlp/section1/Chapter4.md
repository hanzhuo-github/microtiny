---
lang: zh-CN
title: 4. å…±äº« Models å’Œ Tokenizers
description:
article: false
---

[Hugging Face Hub](https://huggingface.co/) æ˜¯ä¸»ç½‘ç«™ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨é‡Œé¢æ‰¾åˆ°å„ç§æœ€æ–°çš„æ¨¡å‹å’Œæ•°æ®é›†ï¼Œä¹Ÿå¯ä»¥ä¸Šä¼ è‡ªå·±çš„æ¨¡å‹å’Œæ•°æ®é›†ã€‚

å…¶ä¸­çš„æ¨¡å‹ä¸å±€é™äº  ğŸ¤— Transformers æˆ–è€… NLPã€‚ä½ å¯ä»¥è‡ªå·±å»æ¢ç´¢ã€‚

æ¨¡å‹éƒ½ç”¨ Git è¿›è¡Œæ‰˜ç®¡ï¼Œå…è®¸ç‰ˆæœ¬æ§åˆ¶å’Œé‡ç°ã€‚å¦å¤–ï¼Œåœ¨ Hub ä¸Šå…±äº«æ¨¡å‹ä¼šè‡ªåŠ¨ä¸ºè¯¥æ¨¡å‹éƒ¨ç½²æ‰˜ç®¡çš„æ¨ç† APIã€‚


## 1. ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹

å¦‚æˆ‘ä»¬è¦ä½¿ç”¨ camembert-base checkpoints.

::: code-tabs#python

@tab pipeline

```python
# ä½¿ç”¨ pipeline
from transformers import pipeline

camembert_fill_mask = pipeline("fill-mask", model="camembert-base")
results = camembert_fill_mask("Le camembert est <mask> :)")
```

@tab model architecture

```python
# ç›´æ¥ä½¿ç”¨ model architecture
from transformers import CamembertTokenizer, CamembertForMaskedLM

tokenizer = CamembertTokenizer.from_pretrained("camembert-base")
model = CamembertForMaskedLM.from_pretrained("camembert-base")
```

@tab Auto* Class

```python Auto*
# æ¨èä½¿ç”¨ Auto* Classï¼Œå› ä¸ºè¿™ç§å®ç°ä¸ architecture æ— å…³
from transformers import AutoTokenizer, AutoModelForMaskedLM

tokenizer = AutoTokenizer.from_pretrained("camembert-base")
model = AutoModelForMaskedLM.from_pretrained("camembert-base")
```

:::

::: tip
ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æ—¶ï¼Œå¯ä»¥åœ¨ model card ä¸­æŸ¥çœ‹å®ƒæ˜¯å¦‚ä½•è®­ç»ƒçš„ï¼Œåœ¨å“ªäº›æ•°æ®é›†ä¸Šè®­ç»ƒçš„ï¼Œå±€é™æ€§å’Œ bias ã€‚
:::

## 2. å…±äº«é¢„è®­ç»ƒæ¨¡å‹

åˆ›å»ºæ¨¡å‹ä»“åº“çš„ä¸‰ç§æ–¹æ³•ï¼š
- ä½¿ç”¨ `push_to_hub` API
- ä½¿ç”¨ `huggingface_hub` python åº“
- åœ¨ web é¡µé¢ä¸Šåˆ›å»º

åˆ›å»ºå¥½ä»“åº“åï¼Œå°±å¯ä»¥é€šè¿‡ git æˆ–è€… git-lfs ä¸Šä¼ æ–‡ä»¶äº†ã€‚

### 2.1 åˆ›å»ºæ¨¡å‹ä»“åº“
#### 2.1.1 ä½¿ç”¨ `push_to_hub` API

ä½ éœ€è¦èº«ä»½ä»¤ç‰Œä¸€é huggingface_hub çŸ¥é“ä½ çš„æƒé™ã€‚

:::code-tabs

@tab Notebook

```python
from huggingface_hub import notebook_login

notebook_login()
```

@tab Terminal

```python
huggingface-cli login
```

:::

å¦‚æœä½ ä½¿ç”¨ Trainer API è®­ç»ƒæ¨¡å‹ï¼Œå°†æ¨¡å‹ä¸Šä¼ è‡³ Hub æœ€ç®€å•çš„æ–¹å¼å°±æ˜¯åœ¨å®šä¹‰ TrainerArguments æ—¶é…ç½® `push_to_hub=True`

```python
from transformers import TrainerArguments

training_args = TrainerArguments(
    "bert-finetuned-mrpc", save_strategy="epoch", push_to_hub=True
)
```

å½“ä½ è°ƒç”¨ `trainer.train()` æ—¶ï¼ŒTrainer ä¼šåœ¨æ¯æ¬¡ä¿å­˜ model æ—¶ï¼ˆæŒ‰ç…§ä¸Šé¢çš„é…ç½®ï¼Œæ˜¯æ¯ä¸ª epochï¼‰å°†ä½ çš„ model ä¸Šä¼ åˆ° Hub ä¸­å¯¹åº”çš„ä»“åº“ä¸Šã€‚ä»“åº“åç§°ä¸ºä½ é€‰æ‹©çš„è¾“å‡ºè·¯å¾„ï¼ˆå¦‚ä¸Šé¢çš„ bert-finetuned-mrpcï¼‰ï¼Œä½ ä¹Ÿå¯ä»¥ç”¨ `hub_model_id="a_different_name"` æ¥è®¾ç½®ä¸åŒçš„åç§°ã€‚å¦‚æœè¦å°† model ä¸Šä¼ åˆ°ä½ æ‰€åœ¨çš„ç»„ç»‡ä¸‹ï¼Œä½ å¯ä»¥ä½¿ç”¨ `hub_model_id="my_organization/mu_repo_name"`ã€‚

è®­ç»ƒç»“æŸåï¼Œä½¿ç”¨ `trainer.push_to_hub()` ä¸Šä¼ æœ€åä¸€ç‰ˆ modelã€‚å®ƒä¼šç”Ÿæˆ model cardã€‚

åœ¨è¾ƒä½å±‚çš„å®ç°ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥é€šè¿‡ modelsã€tokenizersã€configuration å¯¹è±¡çš„ `push_to_hub()` æ–¹æ³•æ¥è®¿é—® Model Hubã€‚è¿™ç§æ–¹å¼æ—¢å¯ä»¥åˆ›å»ºä»“åº“ï¼Œåˆèƒ½å°† model å’Œ tokenizer æ–‡ä»¶ç›´æ¥æ¨åˆ°ä»“åº“ä¸­ã€‚

é¦–å…ˆåˆ›å»º model å’Œ tokenizerã€‚
```python
from transformers import AutoModelForMaskedLM, AutoTokenizer

checkpoint = "camembert-base"

model = AutoModelForMaskedLM.from_pretrained(checkpoint)
tokenizer = AutoTokenizer.from_pretrained(checkpoint)
```

ä½ å¯ä»¥è®­ç»ƒæ¨¡å‹ã€å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒã€å‘ tokenizer ä¸­å¢åŠ  tokensã€‚åšå®Œä½ æƒ³åšçš„äº‹æƒ…æ—¶å€™ï¼Œä½ å¯ä»¥ä½¿ç”¨ `push_to_hub()` å°† model æ¨åˆ°ä»“åº“ä¸­

```python
model.push_to_hub("dummy-model")
```

è¿™å°†ä¼šåˆ›å»ºåä¸º dummy-model çš„ä»“åº“ï¼Œå…¶ä¸­ä¼šå¡«ä¸Šä½ çš„ model æ–‡ä»¶ã€‚

åŒæ ·ï¼Œå¯¹ tokenizer ä¹Ÿå¯åšåŒæ ·çš„æ“ä½œã€‚ç°åœ¨ä½ çš„ä»“åº“ä¸­æœ‰äº†å…¨éƒ¨æ‰€éœ€çš„æ–‡ä»¶ã€‚
```python
tokenizer.push_to_hub("dummy-model")
```

å¦‚æœä½ æƒ³å°†ä»“åº“æ”¾åˆ°ç»„ç»‡ä¸‹ï¼š
```python
tokenizer.push_to_hub("dummy-model", organization="huggingface")
```

å¦‚æœä½ æƒ³ä½¿ç”¨æŸä¸ªç‰¹å®šçš„ Hugging Face tokenï¼š
```python
tokenizer.push_to_hub("dummy-model", organization="huggingface", use_auth_token="<TOKEN>")
```

#### 2.1.2 ä½¿ç”¨ `huggingface_hub` python åº“

ä½ éœ€è¦ä½¿ç”¨ CLI çš„ç™»å½•å‘½ä»¤
```shell
huggingface-cli login
```

huggingface_hub åº“æä¾›äº†å¾ˆå¤šæ–¹æ³•å’Œç±»ã€‚ä¸‹é¢æ˜¯å’Œä»“åº“åˆ›å»ºã€åˆ é™¤ç­‰æœ‰å…³çš„æ–¹æ³•
```python
from huggingface_hub import (
    # User management
    login,
    logout,
    whoami,

    # Repository creation and management
    create_repo,
    delete_repo,
    update_repo_visibility,

    # And some methods to retrieve/change information about the content
    list_models,
    list_datasets,
    list_metrics,
    list_repo_files,
    upload_file,
    delete_file,
)
```

```python
# åˆ›å»ºä»“åº“
from huggingface_hub import create_repo

create_repo("dummy-model")
# å¯ä»¥æŒ‡å®š organization
# create_repo("dummy-model", organization="huggingface")
```

é™¤äº†å¯ä»¥æŒ‡å®š organizationï¼Œè¿˜æœ‰ä¸€äº›å‚æ•°ï¼š
- private: æ˜¯å¦å¯¹å…¶ä»–äººå¯è§
- token: æ˜¯å¦æƒ³ç”¨ç»™å®šçš„ token è¦†ç›–ç¼“å­˜ä¸­çš„ token
- repo_type: æ˜¯éƒ½è¦åˆ›å»º dataset æˆ– spaceï¼ˆè€Œéåˆ›å»º modelï¼‰ã€‚æ¥å—çš„å€¼å¯ä»¥æ˜¯ â€œdatasetâ€ æˆ– â€œspaceâ€


#### 2.1.3 ä½¿ç”¨ web é¡µé¢

è¿™é‡Œä¸å±•å¼€ä»‹ç»ï¼ŒæŒ‰ç…§é¡µé¢æç¤ºè¿›è¡Œå³å¯ã€‚

### 2.2 ä¸Šä¼  model files

Hugging Face Hub çš„æ–‡ä»¶ç®¡ç†ç³»ç»ŸåŸºäº gitï¼ˆå¯¹äº regular filesï¼‰å’Œ git-lfsï¼ˆå¯¹äºå¤§æ–‡ä»¶ï¼Œlarge file storageï¼‰ã€‚

ä¸‹é¢æˆ‘ä»¬å°†ä»‹ç»ä¸‰ç§ä¸Šä¼ æ–‡ä»¶åˆ° Hub çš„æ–¹æ³•ã€‚

#### 2.3.1 `upload_file` æ–¹æ³•

ä½¿ç”¨ `upload_file()` ä¸éœ€è¦ git æˆ– git-lfsï¼Œå®ƒä½¿ç”¨ http post è¯·æ±‚å°†æ–‡ä»¶ç›´æ¥ä¼ åˆ° ğŸ¤— Hubã€‚ä½†æ˜¯å®ƒæ²¡æœ‰åŠæ³•å¤„ç† 5GB ä»¥ä¸Šçš„æ–‡ä»¶ã€‚

```python
from huggingface_hub import upload_file

upload_file(
    "<path_to_file>/config.json",
    path_in_repo="config.json",
    repo_id="<namespace>/dummy-model",
)
```

è¿˜æœ‰ä¸€äº›å…¶ä»–çš„å‚æ•°ï¼š
- token
- repo_type

#### 2.3.2 `Repository` ç±»

`Repository` ç±»ä»¥äº git çš„æ–¹å¼ç®¡ç†æœ¬åœ°ä»“åº“ã€‚ä½¿ç”¨è¯¥ç±»éœ€è¦å®‰è£… git å’Œ git-lfs

:::details å®‰è£… git-lfs

å‚è€ƒ [Git Large File Storage](https://git-lfs.com/)

::: code-tabs#shell
@tab Ubuntu
```shell
curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash
sudo apt-get install git-lfs
```
@tab Mac
```shell
brew install git-lfs
```
:::

:::

æˆ‘ä»¬ä½¿ç”¨åˆšåˆšå»ºå¥½çš„ä»“åº“ã€‚é¦–å…ˆæˆ‘ä»¬å…‹éš†è¿œç«¯ä»“åº“ï¼š
```python
from huggingface_hub import Repository

repo = Repository("<path_to_dummy_folder>", clone_from="<namespace>/dummy-model")
```

è¿™å°†åœ¨æœ¬åœ°åˆ›å»ºæ–‡ä»¶å¤¹<path_to_dummy_folder>ã€‚è¯¥æ–‡ä»¶å¤¹ä¸­åŒ…å« .gitattributes æ–‡ä»¶ã€‚


æˆ‘ä»¬è¿˜ä¼šä½¿ç”¨ä¸€äº›ä¼ ç»Ÿçš„ git æ–¹æ³•ï¼Œå‚è€ƒ[æ–‡æ¡£](https://github.com/huggingface/huggingface_hub/tree/main/src/huggingface_hub#advanced-programmatic-repository-management)ï¼š
```python:no-line-numbers
repo.git_pull()
repo.git_add()
repo.git_commit()
repo.git_push()
repo.git_tag()
```

ç°åœ¨æˆ‘ä»¬æœ‰æƒ³è¦æ¨åˆ° Hub ä¸Šçš„ model å’Œ tokenizerï¼Œå¹¶æˆåŠŸ clone äº†ä»“åº“ã€‚

é¦–å…ˆï¼Œç¡®ä¿æˆ‘ä»¬æœ¬åœ° clone çš„ç‰ˆæœ¬æ˜¯æœ€æ–°çš„ï¼š
```python
repo.git_pull()
```

ç„¶åæˆ‘ä»¬å°±å¯ä»¥ä¿å­˜ model å’Œ tokenizer files äº†ï¼š
```python
model.save_pretrained("<path_to_dummy_folder>")
tokenizer.save_pretrained("<path_to_dummy_folder>")
```

ç›®å‰ï¼Œ<path_to_dummy_folder> ä¸­åŒ…å«äº†å…¨éƒ¨çš„ model å’Œ tokenizer filesã€‚æ¥ä¸‹æ¥å¯ä»¥ä½¿ç”¨ä¼ ç»Ÿçš„ git å·¥ä½œæµå°†ä»–ä»¬æ¨åˆ°è¿œç«¯ hubï¼š
```python
repo.git_add()
repo.git_commit("Add model and tokenizer files")
repo.git_push()
```

#### 2.3.3 `git-based` æ–¹æ³•

ç›´æ¥ä½¿ç”¨ git å’Œ git-lfs æ¥ä¸Šä¼ æ–‡ä»¶ã€‚è¯·ç¡®ä¿å®‰è£…äº† git å’Œ git-lfsã€‚

é¦–å…ˆï¼Œåˆå§‹åŒ– git-lfs
```shell:no-line-numbers
git lfs install
```

æ¥ä¸‹æ¥ï¼Œç¬¬ä¸€æ­¥æ˜¯å…‹éš† model ä»“åº“ï¼š
```shell:no-line-numbers
git clone https://huggingface.co/<namespace>/<your-model-id>
```

ä¾‹å¦‚ï¼Œæˆ‘çš„ username æ˜¯ hanzhuoï¼Œä½¿ç”¨çš„ model name æ˜¯ dummy-model
```shell:no-line-numbers
git clone https://huggingface.co/hanzhuo/dummy-model
```

ç°åœ¨æˆ‘çš„å·¥ä½œè·¯å¾„ä¸­æœ‰ä¸€ä¸ª dummy-model æ–‡ä»¶å¤¹ï¼Œ
```shell:no-line-numbers
cd dummy-model && ls
```

å¯ä»¥ä½¿ç”¨ git æ¥æ·»åŠ å°æ–‡ä»¶ï¼Œå¯¹äºå¤§æ–‡ä»¶ï¼Œéœ€è¦ä½¿ç”¨ git-lfsã€‚

å›é¡¾ä¸€ä¸‹ä¹‹å‰è·å¾— model å’Œ tokenizer çš„æ–¹å¼ï¼š
```python
from transformers import AutoModelForMaskedLM, AutoTokenizer

checkpoint = "camembert-base"

model = AutoModelForMaskedLM.from_pretrained(checkpoint)
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

# Do whatever with the model, train it, fine-tune it...

model.save_pretrained("<path_to_dummy_folder>")
tokenizer.save_pretrained("<path_to_dummy_folder>")
```

æˆ‘ä»¬çœ‹ä¸€ä¸‹ dummy-model ä¸‹çš„æ–‡ä»¶ç›®å½•ï¼š
```:no-line-numbers
config.json  pytorch_model.bin  README.md  sentencepiece.bpe.model  special_tokens_map.json tokenizer_config.json  tokenizer.json
```

å¦‚æœä½¿ç”¨ `ls -lh` å‘½ä»¤ï¼Œå¯ä»¥å‘ç° pytorch_model.bin çš„å¤§å°è¶…è¿‡äº† 400MBã€‚

æ¥ä¸‹æ¥ä½¿ç”¨å¸¸è§„çš„ git å‘½ä»¤ï¼š

```shell:no-line-numbers
git add .
git status
```

```:no-line-numbers
On branch main
Your branch is up to date with 'origin/main'.

Changes to be committed:
  (use "git restore --staged <file>..." to unstage)
  modified:   .gitattributes
	new file:   config.json
	new file:   pytorch_model.bin
	new file:   sentencepiece.bpe.model
	new file:   special_tokens_map.json
	new file:   tokenizer.json
	new file:   tokenizer_config.json
```


å†çœ‹ä¸€ä¸‹ git-lfs ï¼š
```shell:no-line-numbers
git lfs status
```

```:no-line-numbers
On branch main
Objects to be pushed to origin/main:


Objects to be committed:

	config.json (Git: bc20ff2)
	pytorch_model.bin (LFS: 35686c2)
	sentencepiece.bpe.model (LFS: 988bc5a)
	special_tokens_map.json (Git: cb23931)
	tokenizer.json (Git: 851ff3e)
	tokenizer_config.json (Git: f0f7783)

Objects not staged for commit:

```

å¯ä»¥è§‚å¯Ÿåˆ° *pytorch_model.bin* å’Œ *sentencepiece.bpe.model* ä½¿ç”¨çš„ LFSï¼Œå…¶ä½™çš„éƒ½æ˜¯ Gitã€‚

æœ€åï¼Œcommit å¹¶ push
```shell
git commit -m "First model version"
git push
```

## 3. å»ºç«‹ model card

å»ºç«‹ model card æ˜¯é€šè¿‡ *README.md* æ¥å®Œæˆçš„ã€‚ä¸ºäº†ç†è§£ model card çš„é‡è¦ä½œç”¨ï¼Œä½ å¯ä»¥é˜…è¯» [Model Cards for Model Reporting](https://arxiv.org/abs/1810.03993)ã€‚

model card é€šå¸¸å¼€ç¯‡ä¸ºç®€çŸ­çš„æ¦‚è¿°è¯´æ˜å…¶ç”¨é€”ï¼Œç„¶åæ˜¯ä»¥ä¸‹å‡ éƒ¨åˆ†ï¼š
- Model description æè¿°
- Intended uses & limitations é¢„æœŸç”¨é€”å’Œé™åˆ¶
- How to use  å¦‚ä½•ä½¿ç”¨
- Limitations and bias å±€é™æ€§å’Œåè§
- Training data  è®­ç»ƒæ•°æ®
- Training procedure  è®­ç»ƒè¿‡ç¨‹
- Variable & metrics  è¯„ä¼°æŒ‡æ ‡
- Evaluation results  è¯„ä¼°ç»“æœ

### Model card metadata

åœ¨ Hugging Face Hub ä¸­ï¼Œæœ‰çš„ model å±äºç‰¹å®šçš„ç±»å‹ï¼Œä½ å¯ä»¥é€šè¿‡ tasks, languages, libraries ç­‰ç­‰æ¥ç­›é€‰ã€‚

è¯·æŸ¥çœ‹ [camembert-base model card](https://huggingface.co/camembert-base/blob/main/README.md)ï¼Œä½ èƒ½çœ‹åˆ°åœ¨ model card header ä¸­æœ‰å¦‚ä¸‹ä¿¡æ¯ï¼š
```md:no-line-numbers
---
language: fr
license: mit
datasets:
- oscar
---
```

å…·ä½“é…ç½®å¯æŸ¥çœ‹ [full model card specification](https://github.com/huggingface/hub-docs/blame/main/modelcard.md)ã€‚
