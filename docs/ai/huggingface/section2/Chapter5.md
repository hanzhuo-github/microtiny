---
lang: zh-CN
title: 5. ğŸ¤— Datasets åº“
description:
article: false
---

åœ¨[ç¬¬ä¸‰ç« ](../section1/Chapter3.md)ä¸­æˆ‘ä»¬åˆæ­¥ä½“éªŒäº† ğŸ¤— Datasets åº“ï¼Œäº†è§£ fine-tune çš„åŸºæœ¬æ­¥éª¤ï¼š
1. ä» Hugging Face Hub ä¸ŠåŠ è½½æ•°æ®é›†
2. ä½¿ç”¨ `Dataset.map()` é¢„å¤„ç†æ•°æ®
3. åŠ è½½å¹¶è®¡ç®— metrics

åœ¨æœ¬ç« å†…å®¹ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥äº†è§£ ğŸ¤— Datasets åº“ï¼Œä½ å°†èƒ½å¤Ÿå›ç­”ä»¥ä¸‹é—®é¢˜ï¼š
- æ•°æ®é›†ä¸åœ¨ hub ä¸Šåº”è¯¥æ€ä¹ˆåš
- å¦‚ä½•å¯¹æ•°æ®é›†è¿›è¡Œåˆ‡ç‰‡ï¼ˆå¦‚æœä½ ç¡®å®éœ€è¦ä½¿ç”¨ Pandas æ€ä¹ˆåŠï¼‰
- å¦‚æœä½ çš„æ•°æ®é›†å¾ˆå¤§ï¼Œä¼šæ’‘çˆ†ä½ çš„ RAM åº”è¯¥æ€ä¹ˆåŠ
- Memory Mappingã€Apache Arrow æ˜¯ä»€ä¹ˆ
- å¦‚ä½•åˆ›å»ºè‡ªå·±çš„æ•°æ®é›†å¹¶å°†å…¶æ¨è‡³ Hub

## 1. å¤„ç†ä¸åœ¨ Hugging Face Hub ä¸Šçš„æ•°æ®é›†

ğŸ¤— Datasets æä¾›äº†åŠ è½½æœ¬åœ°å’Œè¿œç¨‹æ•°æ®é›†çš„æ–¹æ³•ï¼Œæ”¯æŒä¸‹åˆ—æ ¼å¼ï¼š

|Data format|Loading script|Example|
|:--|:--|:--|
|CSV & TSV|csv|load_dataset("csv", data_files="my_file.csv")|
|Text files|text|load_dataset("text", data_files="my_file.txt")|
|JSON & JSON Lines|json|load_dataset("json", data_files="my_file.jsonl")|
|Pickled DataFrames|pandas|load_dataset("pandas", data_files="my_dataframe.pkl")|

### 1.1 åŠ è½½æœ¬åœ°æ•°æ®é›†

æˆ‘ä»¬ä½¿ç”¨ [SQuAD-it dataset](https://github.com/crux82/squad-it/)ï¼Œå®ƒæ˜¯å¤§è§„æ¨¡æ„å¤§åˆ©è¯­é—®ç­”æ•°æ®é›†ã€‚

:::details Ubuntu ä¸‹è½½å¹¶è§£å‹
```shell
!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-train.json.gz
!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-test.json.gz

!gzip -dkv SQuAD_it-*.json.gz
```
:::

```python
from datasets import load_dataset

squad_it_dataset = load_dataset("json", data_files="SQuAD_it-train.json", field="data")
squad_it_dataset
```

```:no-line-numbers
DatasetDict({
    train: Dataset({
        features: ['paragraphs', 'title'],
        num_rows: 442
    })
})
```

åŠ è½½æœ¬åœ°æ–‡ä»¶ä¼šåˆ›å»ºä¸€ä¸ªå¸¦æœ‰ `train` çš„ `DatasetDict` å¯¹è±¡ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸‹æ ‡æŸ¥çœ‹å‡ ä¸ªç¤ºä¾‹å¦‚ï¼š`squad_it_dataset["train"][0]`ã€‚

å¦‚ä½•è·å¾—åŒæ—¶æœ‰ `train` å’Œ `test` çš„ `DatasetDict` å¯¹è±¡å‘¢ï¼Ÿ

```python
data_files = {"train": "SQuAD_it-train.json", "test": "SQuAD_it-test.json"}
squad_it_dataset = load_dataset("json", data_files=data_files, field="data")
squad_it_dataset
```

```no-line-numbers
DatasetDict({
    train: Dataset({
        features: ['paragraphs', 'title'],
        num_rows: 442
    })
    test: Dataset({
        features: ['paragraphs', 'title'],
        num_rows: 48
    })
})
```

:::tip
data_files å‚æ•°å¾ˆçµæ´»ï¼Œå¯ä»¥æ˜¯å•ä¸ªæ–‡ä»¶è·¯å¾„ã€æ–‡ä»¶è·¯å¾„ listã€æ˜ å°„åç§°è·¯å¾„çš„å­—å…¸ï¼Œè¿˜å¯ä»¥ä½¿ç”¨ Unix shell çš„åŒ¹é…è§„åˆ™é€‰æ‹©å¤šæœ‰æ»¡è¶³è§„åˆ™çš„æ–‡ä»¶ï¼ˆå¦‚ `data_files="*.json"` åŒ¹é…æ‰€æœ‰çš„ json æ–‡ä»¶ï¼‰ã€‚
:::

ğŸ¤— Datasets çš„ loading script æ”¯æŒè‡ªåŠ¨è§£å‹ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥è·³è¿‡è‡ªå·±è§£å‹çš„è¿‡ç¨‹ï¼Œç›´æ¥ä½¿ç”¨ä¸‹é¢çš„ä»£ç åŠ è½½æ•°æ®ï¼š
```python
data_files = {"train": "SQuAD_it-train.json.gz", "test": "SQuAD_it-test.json.gz"}
squad_it_dataset = load_dataset("json", data_files=data_files, field="data")
```


### 1.2 åŠ è½½è¿œç¨‹æ•°æ®é›†

å°† `data_files` è®¾ç½®ä¸º url å³å¯ã€‚

```python
url = "https://github.com/crux82/squad-it/raw/master/"
data_files = {
    "train": url + "SQuAD_it-train.json.gz",
    "test": url + "SQuAD_it-test.json.gz",
}
squad_it_dataset = load_dataset("json", data_files=data_files, field="data")
```

## 2. åˆ‡ç‰‡

### 2.1 Slicing and dicing æ•°æ®

å’Œ Pandas ç±»ä¼¼ï¼ŒğŸ¤— Datasets ä¹Ÿæä¾›äº†ä¸€äº›å‡½æ•°å¤„ç† `Dataset` å’Œ `DatasetDict` å¯¹è±¡ã€‚åœ¨[ç¬¬ä¸‰ç« ](../section1/Chapter3.md)ä¸­æˆ‘ä»¬ä»‹ç»äº† `Dataset.map()`ï¼Œæœ¬ç« æˆ‘ä»¬å°†ä»‹ç»å…¶ä»–å‡½æ•°ã€‚

æ¥ä¸‹æ¥æˆ‘ä»¬ä½¿ç”¨çš„æ•°æ®é›†ä¸º [Drug Review Dataset](https://archive.ics.uci.edu/dataset/462/drug+review+dataset+drugs+com)ã€‚

TSV æ˜¯ CSV çš„å˜ä½“ï¼Œå®ƒå’Œ CSV çš„åŒºåˆ«åœ¨äº CSV ç”¨é€—å·ä½œä¸ºåˆ†å‰²ç¬¦ï¼Œè€Œ TSV ä½¿ç”¨åˆ¶è¡¨ç¬¦ä½œä¸ºåˆ†éš”ç¬¦ã€‚æ‰€ä»¥æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ csv åŠ è½½çš„æ–¹å¼å¹¶æŒ‡å®š delimiterã€‚

```python
from datasets import load_dataset

data_files = {"train": "drugLibTrain_raw.tsv", "test": "drugLibTest_raw.tsv"}
drug_dataset = load_dataset("csv", data_files=data_files, delimiter="\t")
```

æˆ‘ä»¬å¯ä»¥æŠ½å–ä¸€äº›æ ·æœ¬æ¥è§‚å¯Ÿï¼Œä»¥å¯¹æ•°æ®æœ‰ä¸€ä¸ªç›´è§‚çš„è®¤è¯†ã€‚å¯ä»¥ä½¿ç”¨ `Dataset.shuffle()` å’Œ `Dataset.select()` æ¥éšæœºæŠ½å–æ ·æœ¬ã€‚

```python
drug_sample = drug_dataset["train"].shuffle().select(range(1000))

# é€‰å–å‰é¢å‡ ä¸ªæ ·æœ¬
drug_sample[:3]
```

:::details è¿è¡Œç»“æœ
```:no-line-numbers
{'Unnamed: 0': [1468, 3422, 1444],
 'urlDrugName': ['cymbalta', 'tazorac', 'tirosint'],
 'rating': [9, 5, 4],
 'effectiveness': ['Highly Effective',
  'Moderately Effective',
  'Moderately Effective'],
 'sideEffects': ['No Side Effects',
  'Severe Side Effects',
  'Moderate Side Effects'],
 'condition': ['sever depression',
  'acne',
  'thyroid/total thyroidectomy due to cancer'],
 'benefitsReview': ["This medication saved my life. The depression had gotten so sever that I was unable to function properly. It has made me feel like a 'real' person again. It has not done much for the anxiety, panic, or OCD. The Xanax helps with that area. I will be going to the psychiatrist in 2 weeks for the anxiety, panic, and OCD. Hoping to stay on the Cymbalta. I was on Lexapro 30mg from 2000-2006. Then switched to Celexa (cost reasons) 60mg from 2007-2008. The Celexa just about costed me my life. It was ineffective for the Depression. Try not to take Celexa for cost reasons, Lexapro shows much more promise in its effectiveness.",
  'It exfoliated my skin.',
  'I started taking Tirosint 125mcg 6 weeks ago due to a gluten and caseine allergy. I previously was taking synthroid however, the company couldnt verify the inactive ingredients. So to avoid gluten, caseine, and some really nasty anxiety symptms I switched to the Tirosint. \r\r\n\r\r\nThe anxiety symptoms subsided from 1 attack per day to none. This was great!, but then new symptoms started after three weeks.'],
 'sideEffectsReview': ['Weight gain, which is to be expected when you "feel better"',
  'My skin became extremely dry, irritated, red, and would peel.',
  'I felt dperessed, tired and very sore. My finger joints hurt so bad and to the touch. My back, and legs ached. Then my lower legs, ankles and feet started to swell. it is so bad that I cannot walk upon waking in the morning. If Im on my feet for more than an hour I have to elevate my legs due to the pain and swelling. I also gained alot of weight 8lbs. I\'m a healthy 37 year old woman, I am active with two small boys, and eat an extremley healthy diet due to my Celiacs and Caseine allergies. \r\r\n\r\r\nI recently had my blood levels checked and to my surprise I was taking way too much Tirosint. My Endo said that the swelling and pain wasnt from the Tirosint and that I should see my Primary doctor...REALLY??  I was shocked due to my "hypo" symptoms. Im thinking of returning to Synthroid and switching doctors...'],
 'commentsReview': ['Depression and Anxiety',
  'Use once daily, at night.  Wash face, use toner and leave to dry (10 minutes).  Then apply pea size amount of cream all over face, excluding eye area.  Let soak in (15 minutes), then layer with moisturizer.  Must wear sunscreen daily.',
  '125 mcg Tirosint per day and doubled on Sat and Sun. \r\r\n\r\r\nListen to your body and be persistent with your doctors.']}
```
:::


`Dataset.select()` éœ€è¦ä¼ å…¥ä¸€ä¸ªå¯è¿­ä»£çš„ç´¢å¼•ï¼Œè¿™é‡Œæˆ‘ä»¬ä¼ å…¥äº† `range(1000)` ä»éšæœºæ‰“ä¹±çš„æ•°æ®é›†ä¸­é€‰å–å‰ 1000 ä¸ªæ ·æœ¬ã€‚æˆ‘ä»¬å¯ä»¥çœ‹å‡ºæ•°æ®é›†çš„ä¸€äº›ç‰¹ç‚¹äº†ï¼š
- `Unnamed: 0`: å¯èƒ½æ˜¯æ‚£è€…çš„ ID
- `condition`: æè¿°å¥åº·çŠ¶å†µçš„æ ‡ç­¾ï¼Œæœ‰å¤§å†™æœ‰å°å†™
- å„ç±» review: é•¿çŸ­ä¸ä¸€ï¼Œæ··æœ‰ Python è¡Œåˆ†éš”ç¬¦ï¼ˆ\r\nï¼‰ã€html å­—ç¬¦ç¼–ç ï¼ˆè§ ğŸ¤— å®˜æ–¹ç¤ºä¾‹ï¼Œå¦‚`&#039;`ï¼‰

ä¸‹é¢æˆ‘ä»¬éªŒè¯ä¸€ä¸‹ Unnamed 0 æ˜¯æ‚£è€… ID çš„çŒœæƒ³ï¼Œè¿™é‡Œä¼šç”¨åˆ° `Dataset.unique()`ï¼š

```python
for split in drug_dataset.keys():
    assert len(drug_dataset[split]) == len(drug_dataset[split].unique("Unnamed: 0"))
```

ä¸Šé¢çš„ä»£ç æ²¡æŠ›å‡º `AssertionError`ï¼Œçœ‹æ¥æ˜¯æ‚£è€… ID çš„è¿™ä¸ªæƒ³æ³•æ˜¯æ­£ç¡®çš„ã€‚æˆ‘ä»¬å°†è¯¥åˆ—é‡å‘½åä¸º patient_idï¼Œè¿™é‡Œä¼šç”¨åˆ° `DatasetDict.rename_column()`:

```python
drug_dataset = drug_dataset.rename_column(
    original_column_name="Unnamed: 0", new_column_name="patient_id"
)
```

æˆ‘ä»¬ä½¿ç”¨ `Dataset.map()` æ ‡å‡†åŒ–æ‰€æœ‰çš„ conditionï¼š
```python
def lowercase_condition(example):
    return {"condition": example["condition"].lower()}


drug_dataset.map(lowercase_condition)
```

```:no-line-numbers
AttributeError: 'NoneType' object has no attribute 'lower'
```

çœ‹æ¥æˆ‘ä»¬è¿˜éœ€è¦æŠŠ condition ä¸º None çš„æ•°æ®è¿‡æ»¤æ‰ï¼ˆä½¿ç”¨ `Dataset.filter()`ï¼‰ï¼š
```python
drug_dataset = drug_dataset.filter(lambda x: x["condition"] is not None)
```

### 2.2 åˆ›å»ºæ–°åˆ—

åœ¨å¤„ç† review å­—æ®µæ—¶ï¼Œæœ€å¥½æ˜¯è¦ç»Ÿè®¡ä¸€ä¸‹å­—æ•°ã€‚æˆ‘ä»¬å°±ç®€å•åŸºäºç©ºæ ¼æ¥è¿›è¡Œè¯æ•°ç»Ÿè®¡ã€‚

```python
def compute_review_length(example):
    return {"benefit_review_length": len(example["benefitsReview"].split())}

drug_dataset = drug_dataset.map(compute_review_length)
```

è¿™æ ·ï¼Œæˆ‘ä»¬å°±å¢åŠ äº† benefit_review_length åˆ—ã€‚æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨ `Dataset.sort()` ä»¥è¯¥åˆ—ä¸ºåŸºå‡†åšæ’åº
```python
drug_datasets["train"].sort("benefit_review_length")
```

:::tip `Dataset.add_column()`
æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨ `Dataset.add_column()` å¢åŠ åˆ—ã€‚å¯ä»¥ä¼ å…¥ Python list æˆ– numpyã€‚
:::

review çš„è¯æ•°è¾ƒå°‘æ—¶ï¼ˆæç«¯æƒ…å†µæ¯”å¦‚åªæœ‰ä¸€ä¸ªè¯ï¼‰å¯¹äºé¢„æµ‹æ²¡æœ‰æä¾›ç›¸å¯¹æœ‰ç”¨çš„ä¿¡æ¯ã€‚ä¸‹é¢æˆ‘å°†ä½¿ç”¨ Dataset.filter() å°†å°‘äº 30 ä¸ªè¯çš„ review å»æ‰ã€‚

```python
drug_dataset = drug_dataset.filter(lambda x: x["benefit_review_length"] > 30)
print(drug_dataset.num_rows)
```
```:no-line-numbers
{'train': 1445, 'test': 473}
```

review ä¸­è¿˜æœ‰ä¸€äº› html ç¼–ç ï¼Œå¯ä»¥ä½¿ç”¨ Python çš„ html module æ¥è§£ç ï¼š
```python
import html

text = "I&#039;m a transformer called BERT"
html.unescape(text)
```

```:no-line-numbers
"I'm a transformer called BERT"
```

```python
drug_dataset = drug_dataset.map(lambda x: { "benefitsReview": html.unescape(x["benefitsReview"])})
```

### 2.3 `map()` æ–¹æ³•

`Dataset.map()` æœ‰ä¸€ä¸ªå‚æ•°æ˜¯ `batched`ã€‚å°†å…¶è®¾ä¸º True åï¼Œmap å‡½æ•°å°†ä¸€æ¬¡å¤„ç†å¤šä¸ªæ•°æ®ï¼ˆæˆä¸ºä¸€æ‰¹ a batchï¼‰ï¼Œbatch size å¯ä»¥é…ç½®ï¼Œé»˜è®¤æƒ…å†µä¸‹ä¸º 1000.